Search.setIndex({"docnames": ["_autosummary/mt_transformer", "_autosummary/mt_transformer.config", "_autosummary/mt_transformer.config.project_config", "_autosummary/mt_transformer.config.project_config.Config", "_autosummary/mt_transformer.data_handler", "_autosummary/mt_transformer.data_handler.data_loader", "_autosummary/mt_transformer.data_handler.data_loader.create_tokenizers_dataloaders", "_autosummary/mt_transformer.data_handler.data_loader.get_raw_data_opus_books", "_autosummary/mt_transformer.data_handler.data_tokenizer", "_autosummary/mt_transformer.data_handler.data_tokenizer.check_max_seq_length", "_autosummary/mt_transformer.data_handler.data_tokenizer.get_all_text_sequences_from_dataset_in_language", "_autosummary/mt_transformer.data_handler.data_tokenizer.get_or_create_tokenizer", "_autosummary/mt_transformer.data_handler.masks", "_autosummary/mt_transformer.data_handler.masks.causal_mask", "_autosummary/mt_transformer.data_handler.two_language_data_set", "_autosummary/mt_transformer.data_handler.two_language_data_set.TwoLanguagesDataset", "_autosummary/mt_transformer.inference", "_autosummary/mt_transformer.inference.tf_inference", "_autosummary/mt_transformer.inference.tf_inference.TfInference", "_autosummary/mt_transformer.inference.tf_visualizer", "_autosummary/mt_transformer.inference.tf_visualizer.TfVisualizer", "_autosummary/mt_transformer.model", "_autosummary/mt_transformer.model.greedy_decoder", "_autosummary/mt_transformer.model.greedy_decoder.GreedyDecoder", "_autosummary/mt_transformer.model.layers", "_autosummary/mt_transformer.model.layers.FeedForwardBlock", "_autosummary/mt_transformer.model.layers.LayerNormalization", "_autosummary/mt_transformer.model.layers.MultiHeadAttention", "_autosummary/mt_transformer.model.layers.PositionalEncoding", "_autosummary/mt_transformer.model.layers.ProjectionLayer", "_autosummary/mt_transformer.model.layers.ResidualConnection", "_autosummary/mt_transformer.model.layers.TokenEmbeddings", "_autosummary/mt_transformer.model.transformer_model", "_autosummary/mt_transformer.model.transformer_model.Decoder", "_autosummary/mt_transformer.model.transformer_model.DecoderStack", "_autosummary/mt_transformer.model.transformer_model.Encoder", "_autosummary/mt_transformer.model.transformer_model.EncoderStackOld", "_autosummary/mt_transformer.model.transformer_model.Transformer", "_autosummary/mt_transformer.model.transformer_model.TransformerModel", "_autosummary/mt_transformer.model.transformer_model.create_transformer", "_autosummary/mt_transformer.model.transformer_model.get_transformer_model", "_autosummary/mt_transformer.trainer", "_autosummary/mt_transformer.trainer.transformer_trainer", "_autosummary/mt_transformer.trainer.transformer_trainer.TransformerTrainer", "_autosummary/mt_transformer.trainer.transformer_validator", "_autosummary/mt_transformer.trainer.transformer_validator.TransformerValidator", "_autosummary/mt_transformer.utils", "_autosummary/mt_transformer.utils.tf_utils", "_autosummary/mt_transformer.utils.tf_utils.get_proc_device", "api", "index", "intro", "transformer/embeddings", "transformer/index"], "filenames": ["_autosummary/mt_transformer.rst", "_autosummary/mt_transformer.config.rst", "_autosummary/mt_transformer.config.project_config.rst", "_autosummary/mt_transformer.config.project_config.Config.rst", "_autosummary/mt_transformer.data_handler.rst", "_autosummary/mt_transformer.data_handler.data_loader.rst", "_autosummary/mt_transformer.data_handler.data_loader.create_tokenizers_dataloaders.rst", "_autosummary/mt_transformer.data_handler.data_loader.get_raw_data_opus_books.rst", "_autosummary/mt_transformer.data_handler.data_tokenizer.rst", "_autosummary/mt_transformer.data_handler.data_tokenizer.check_max_seq_length.rst", "_autosummary/mt_transformer.data_handler.data_tokenizer.get_all_text_sequences_from_dataset_in_language.rst", "_autosummary/mt_transformer.data_handler.data_tokenizer.get_or_create_tokenizer.rst", "_autosummary/mt_transformer.data_handler.masks.rst", "_autosummary/mt_transformer.data_handler.masks.causal_mask.rst", "_autosummary/mt_transformer.data_handler.two_language_data_set.rst", "_autosummary/mt_transformer.data_handler.two_language_data_set.TwoLanguagesDataset.rst", "_autosummary/mt_transformer.inference.rst", "_autosummary/mt_transformer.inference.tf_inference.rst", "_autosummary/mt_transformer.inference.tf_inference.TfInference.rst", "_autosummary/mt_transformer.inference.tf_visualizer.rst", "_autosummary/mt_transformer.inference.tf_visualizer.TfVisualizer.rst", "_autosummary/mt_transformer.model.rst", "_autosummary/mt_transformer.model.greedy_decoder.rst", "_autosummary/mt_transformer.model.greedy_decoder.GreedyDecoder.rst", "_autosummary/mt_transformer.model.layers.rst", "_autosummary/mt_transformer.model.layers.FeedForwardBlock.rst", "_autosummary/mt_transformer.model.layers.LayerNormalization.rst", "_autosummary/mt_transformer.model.layers.MultiHeadAttention.rst", "_autosummary/mt_transformer.model.layers.PositionalEncoding.rst", "_autosummary/mt_transformer.model.layers.ProjectionLayer.rst", "_autosummary/mt_transformer.model.layers.ResidualConnection.rst", "_autosummary/mt_transformer.model.layers.TokenEmbeddings.rst", "_autosummary/mt_transformer.model.transformer_model.rst", "_autosummary/mt_transformer.model.transformer_model.Decoder.rst", "_autosummary/mt_transformer.model.transformer_model.DecoderStack.rst", "_autosummary/mt_transformer.model.transformer_model.Encoder.rst", "_autosummary/mt_transformer.model.transformer_model.EncoderStackOld.rst", "_autosummary/mt_transformer.model.transformer_model.Transformer.rst", "_autosummary/mt_transformer.model.transformer_model.TransformerModel.rst", "_autosummary/mt_transformer.model.transformer_model.create_transformer.rst", "_autosummary/mt_transformer.model.transformer_model.get_transformer_model.rst", "_autosummary/mt_transformer.trainer.rst", "_autosummary/mt_transformer.trainer.transformer_trainer.rst", "_autosummary/mt_transformer.trainer.transformer_trainer.TransformerTrainer.rst", "_autosummary/mt_transformer.trainer.transformer_validator.rst", "_autosummary/mt_transformer.trainer.transformer_validator.TransformerValidator.rst", "_autosummary/mt_transformer.utils.rst", "_autosummary/mt_transformer.utils.tf_utils.rst", "_autosummary/mt_transformer.utils.tf_utils.get_proc_device.rst", "api.rst", "index.md", "intro.rst", "transformer/embeddings.rst", "transformer/index.md"], "titles": ["mt_transformer", "mt_transformer.config", "mt_transformer.config.project_config", "mt_transformer.config.project_config.Config", "mt_transformer.data_handler", "mt_transformer.data_handler.data_loader", "mt_transformer.data_handler.data_loader.create_tokenizers_dataloaders", "mt_transformer.data_handler.data_loader.get_raw_data_opus_books", "mt_transformer.data_handler.data_tokenizer", "mt_transformer.data_handler.data_tokenizer.check_max_seq_length", "mt_transformer.data_handler.data_tokenizer.get_all_text_sequences_from_dataset_in_language", "mt_transformer.data_handler.data_tokenizer.get_or_create_tokenizer", "mt_transformer.data_handler.masks", "mt_transformer.data_handler.masks.causal_mask", "mt_transformer.data_handler.two_language_data_set", "mt_transformer.data_handler.two_language_data_set.TwoLanguagesDataset", "mt_transformer.inference", "mt_transformer.inference.tf_inference", "mt_transformer.inference.tf_inference.TfInference", "mt_transformer.inference.tf_visualizer", "mt_transformer.inference.tf_visualizer.TfVisualizer", "mt_transformer.model", "mt_transformer.model.greedy_decoder", "mt_transformer.model.greedy_decoder.GreedyDecoder", "mt_transformer.model.layers", "mt_transformer.model.layers.FeedForwardBlock", "mt_transformer.model.layers.LayerNormalization", "mt_transformer.model.layers.MultiHeadAttention", "mt_transformer.model.layers.PositionalEncoding", "mt_transformer.model.layers.ProjectionLayer", "mt_transformer.model.layers.ResidualConnection", "mt_transformer.model.layers.TokenEmbeddings", "mt_transformer.model.transformer_model", "mt_transformer.model.transformer_model.Decoder", "mt_transformer.model.transformer_model.DecoderStack", "mt_transformer.model.transformer_model.Encoder", "mt_transformer.model.transformer_model.EncoderStackOld", "mt_transformer.model.transformer_model.Transformer", "mt_transformer.model.transformer_model.TransformerModel", "mt_transformer.model.transformer_model.create_transformer", "mt_transformer.model.transformer_model.get_transformer_model", "mt_transformer.trainer", "mt_transformer.trainer.transformer_trainer", "mt_transformer.trainer.transformer_trainer.TransformerTrainer", "mt_transformer.trainer.transformer_validator", "mt_transformer.trainer.transformer_validator.TransformerValidator", "mt_transformer.utils", "mt_transformer.utils.tf_utils", "mt_transformer.utils.tf_utils.get_proc_device", "&lt;no title&gt;", "How to implement a Transformer ?", "Introduction", "The Embeddings Layer", "Transformer"], "terms": {"document": [0, 50], "src": 0, "folder": 0, "class": [2, 3, 14, 15, 17, 18, 19, 20, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 42, 43, 44, 45], "sourc": [3, 6, 7, 9, 10, 11, 13, 15, 18, 20, 23, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 43, 45, 48], "base": [3, 15, 18, 20, 23, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 43, 45], "object": [3, 18, 20, 23, 43, 45], "configur": [3, 6, 7, 11, 43], "method": [3, 15, 18, 20, 23, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 43, 45], "get_experiments_file_path": 3, "get": [3, 10, 11, 48, 50], "file": 3, "path": 3, "experi": 3, "return": [3, 6, 7, 9, 10, 11, 28, 31, 34, 36, 39, 48], "type": [3, 6, 7, 9, 10, 11, 28, 31, 39, 48], "get_rel_dictionary_file_path": 3, "languag": [3, 9, 10, 11], "construct": 3, "rel": 3, "dictionari": [3, 31], "specif": 3, "paramet": [3, 6, 7, 9, 10, 11, 27, 28, 31, 34, 36, 43], "str": [3, 9, 10, 11, 48], "get_saved_model_file_path": 3, "epoch": 3, "save": 3, "model": [3, 50, 51, 52], "load": [3, 7], "specifi": 3, "function": [5, 8, 12, 32, 47], "config": [6, 7, 11, 18, 20, 38, 40, 43], "creat": [6, 11], "token": [6, 9, 11, 28, 31, 36, 52], "data": [6, 7, 9, 10, 11], "loader": 6, "train": [6, 43], "valid": 6, "target": [6, 31], "vocabulari": 6, "dataload": 6, "raw": [7, 9, 11], "set": [7, 9, 10, 11], "opu": [7, 9, 11], "book": [7, 9, 11], "from": [7, 51], "hug": [7, 11], "face": [7, 11], "dataset": [7, 9, 10, 11, 15], "ds_raw": [9, 10, 11, 15], "check": [9, 30, 50], "maximum": 9, "sequenc": [9, 10, 28, 31], "length": [9, 28, 31], "none": [9, 10], "all": [10, 50, 51, 53], "text": [10, 31], "form": 10, "given": [10, 11], "_description_": 10, "yield": 10, "iter": 10, "over": 10, "everi": [10, 28, 31, 50, 51], "sentenc": 10, "gener": 10, "ani": [10, 28, 31], "provid": [11, 50, 51], "size": [13, 31], "tokenizer_src": 15, "tokenizer_tgt": 15, "src_lang": 15, "tgt_lang": 15, "seq_len": [15, 28], "d_model": [25, 27, 28, 29, 31, 39], "d_ff": [25, 38, 39], "dropout": [25, 30, 34, 36, 38, 39], "modul": [25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38], "attribut": [25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38], "ep": 26, "1e": 26, "06": 26, "http": [26, 31, 50, 51], "www": 26, "pinecon": 26, "io": 26, "learn": [26, 28, 31, 50, 51, 53], "batch": [26, 28, 31], "normal": [26, 30], "num_head": 27, "dropout_prob": [27, 28], "multi": 27, "head": 27, "attent": [27, 50, 51, 53], "int": [27, 28, 31], "number": [27, 28, 31, 52], "embed": [27, 31, 53], "featur": [27, 28, 31, 52], "float": [27, 28], "probabl": [27, 28], "drop": [27, 28], "out": [27, 28, 50], "The": [28, 31, 43, 50, 51, 53], "posit": [28, 31], "encod": [28, 31, 37], "hold": [28, 31], "tensor": [28, 31], "precomput": 28, "valu": 28, "per": [28, 31], "drop_out_prob": 28, "forward": [28, 31, 34, 36], "x": [28, 31, 34, 36], "add": [28, 30], "previou": [28, 30], "which": 28, "usual": 28, "contain": 28, "input": 28, "shape": 28, "i": [28, 31, 48, 50, 51, 53], "dim": [28, 31], "requires_grad_": 28, "fals": 28, "tell": 28, "ar": [28, 31, 51, 53], "A": [28, 31, 50, 51, 53], "appli": [28, 31], "result": 28, "vocab_s": 29, "current": [30, 50, 51], "first": 30, "sublay": 30, "norm": 30, "vice": 30, "versa": 30, "dictionary_s": 31, "fix": 31, "comput": [31, 50], "For": 31, "map": 31, "num_batch": 31, "sequence_length": 31, "perform": 31, "multipli": 31, "sqrt": [31, 52], "scale": [31, 53], "origin": [31, 50, 51, 52, 53], "paper": [31, 52, 53], "doe": 31, "explain": 31, "why": 31, "datasci": 31, "stackexchang": 31, "com": 31, "question": 31, "87906": 31, "transform": [31, 39, 51], "word": 31, "befor": 31, "ad": 31, "todo": 31, "should": 31, "layer": [33, 35], "self_attention_block": [34, 36], "cross_attention_block": 34, "feed_forward_block": [34, 36], "encoder_output": 34, "src_mask": [34, 36], "tgt_mask": 34, "establish": 34, "causal": 34, "mask": 36, "avoid": 36, "actual": 36, "interact": 36, "pad": 36, "decod": 37, "src_emb": 37, "tgt_emb": 37, "src_po": 37, "tgt_po": 37, "projection_lay": 37, "num_stack": [38, 39], "6": [38, 39], "h": [38, 39], "8": [38, 39], "0": [38, 39, 52], "1": [38, 39], "2048": [38, 39], "src_vocab_s": 39, "tgt_vocab_s": 39, "src_seq_len": 39, "tgt_seq_len": 39, "512": 39, "vocab_src_len": 40, "vocab_tgt_len": 40, "import": [42, 47], "handl": 43, "flow": 43, "processor": 48, "either": 48, "cuda": 48, "cpu": 48, "string": 48, "devic": 48, "architectur": [50, 51, 53], "power": [50, 51], "almost": [50, 51], "state": [50, 51], "art": [50, 51], "deep": [50, 51], "here": [50, 51], "we": [50, 51], "an": [50, 51], "publish": [50, 51], "vaswani": [50, 51, 52, 53], "et": [50, 51, 53], "al": [50, 51, 53], "you": [50, 51, 52, 53], "need": [50, 51, 53], "2017": [50, 51, 53], "arxiv": [50, 51], "org": [50, 51], "ab": [50, 51], "1706": [50, 51], "03762": [50, 51], "would": 50, "like": 50, "us": [50, 52], "other": 50, "your": 50, "own": 50, "solut": [50, 53], "technic": 50, "strateg": 50, "manag": 50, "servic": 50, "artifici": 50, "intellig": 50, "quantum": 50, "contact": 50, "u": 50, "find": 50, "can": [50, 52], "support": 50, "understand": 50, "detail": 50, "code": 50, "refer": [50, 52], "gmbh": 50, "more": 50, "about": 50, "our": 50, "how": [51, 53], "implement": [51, 52], "scratch": 51, "thi": [51, 52], "project": 51, "under": 51, "activ": 51, "develop": 51, "stai": 51, "tune": 51, "let": 51, "know": 51, "when": 51, "readi": 51, "well": 52, "googl": 52, "mention": 52, "d_": 52, "where": 52, "each": 52, "howev": 52, "neither": 52, "nor": 52, "frac": 52, "sum_": 52, "t": 52, "n": 52, "f": 52, "k": 52, "Or": 52, "want": 52, "write": 52, "inlin": 52, "build": 53, "machin": 53, "translat": 53, "propos": 53, "what": 53, "my": 53, "take": 53}, "objects": {"": [[0, 0, 0, "-", "mt_transformer"]], "mt_transformer": [[1, 0, 0, "-", "config"], [4, 0, 0, "-", "data_handler"], [16, 0, 0, "-", "inference"], [21, 0, 0, "-", "model"], [41, 0, 0, "-", "trainer"], [46, 0, 0, "-", "utils"]], "mt_transformer.config": [[2, 0, 0, "-", "project_config"]], "mt_transformer.config.project_config": [[3, 1, 1, "", "Config"]], "mt_transformer.config.project_config.Config": [[3, 2, 1, "", "get_experiments_file_path"], [3, 2, 1, "", "get_rel_dictionary_file_path"], [3, 2, 1, "", "get_saved_model_file_path"]], "mt_transformer.data_handler": [[5, 0, 0, "-", "data_loader"], [8, 0, 0, "-", "data_tokenizer"], [12, 0, 0, "-", "masks"], [14, 0, 0, "-", "two_language_data_set"]], "mt_transformer.data_handler.data_loader": [[6, 3, 1, "", "create_tokenizers_dataloaders"], [7, 3, 1, "", "get_raw_data_opus_books"]], "mt_transformer.data_handler.data_tokenizer": [[9, 3, 1, "", "check_max_seq_length"], [10, 3, 1, "", "get_all_text_sequences_from_dataset_in_language"], [11, 3, 1, "", "get_or_create_tokenizer"]], "mt_transformer.data_handler.masks": [[13, 3, 1, "", "causal_mask"]], "mt_transformer.data_handler.two_language_data_set": [[15, 1, 1, "", "TwoLanguagesDataset"]], "mt_transformer.inference": [[17, 0, 0, "-", "tf_inference"], [19, 0, 0, "-", "tf_visualizer"]], "mt_transformer.inference.tf_inference": [[18, 1, 1, "", "TfInference"]], "mt_transformer.inference.tf_visualizer": [[20, 1, 1, "", "TfVisualizer"]], "mt_transformer.model": [[22, 0, 0, "-", "greedy_decoder"], [24, 0, 0, "-", "layers"], [32, 0, 0, "-", "transformer_model"]], "mt_transformer.model.greedy_decoder": [[23, 1, 1, "", "GreedyDecoder"]], "mt_transformer.model.layers": [[25, 1, 1, "", "FeedForwardBlock"], [26, 1, 1, "", "LayerNormalization"], [27, 1, 1, "", "MultiHeadAttention"], [28, 1, 1, "", "PositionalEncoding"], [29, 1, 1, "", "ProjectionLayer"], [30, 1, 1, "", "ResidualConnection"], [31, 1, 1, "", "TokenEmbeddings"]], "mt_transformer.model.layers.PositionalEncoding": [[28, 2, 1, "", "forward"]], "mt_transformer.model.layers.TokenEmbeddings": [[31, 2, 1, "", "forward"]], "mt_transformer.model.transformer_model": [[33, 1, 1, "", "Decoder"], [34, 1, 1, "", "DecoderStack"], [35, 1, 1, "", "Encoder"], [36, 1, 1, "", "EncoderStackOld"], [37, 1, 1, "", "Transformer"], [38, 1, 1, "", "TransformerModel"], [39, 3, 1, "", "create_transformer"], [40, 3, 1, "", "get_transformer_model"]], "mt_transformer.model.transformer_model.DecoderStack": [[34, 2, 1, "", "forward"]], "mt_transformer.model.transformer_model.EncoderStackOld": [[36, 2, 1, "", "forward"]], "mt_transformer.trainer": [[42, 0, 0, "-", "transformer_trainer"], [44, 0, 0, "-", "transformer_validator"]], "mt_transformer.trainer.transformer_trainer": [[43, 1, 1, "", "TransformerTrainer"]], "mt_transformer.trainer.transformer_validator": [[45, 1, 1, "", "TransformerValidator"]], "mt_transformer.utils": [[47, 0, 0, "-", "tf_utils"]], "mt_transformer.utils.tf_utils": [[48, 3, 1, "", "get_proc_device"]]}, "objtypes": {"0": "py:module", "1": "py:class", "2": "py:method", "3": "py:function"}, "objnames": {"0": ["py", "module", "Python module"], "1": ["py", "class", "Python class"], "2": ["py", "method", "Python method"], "3": ["py", "function", "Python function"]}, "titleterms": {"mt_transform": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48], "config": [1, 2, 3], "project_config": [2, 3], "data_handl": [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], "data_load": [5, 6, 7], "create_tokenizers_dataload": 6, "get_raw_data_opus_book": 7, "data_token": [8, 9, 10, 11], "check_max_seq_length": 9, "get_all_text_sequences_from_dataset_in_languag": 10, "get_or_create_token": 11, "mask": [12, 13], "causal_mask": 13, "two_language_data_set": [14, 15], "twolanguagesdataset": 15, "infer": [16, 17, 18, 19, 20], "tf_infer": [17, 18], "tfinfer": 18, "tf_visual": [19, 20], "tfvisual": 20, "model": [21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40], "greedy_decod": [22, 23], "greedydecod": 23, "layer": [24, 25, 26, 27, 28, 29, 30, 31, 52, 53], "feedforwardblock": 25, "layernorm": 26, "multiheadattent": 27, "positionalencod": 28, "projectionlay": 29, "residualconnect": 30, "tokenembed": 31, "transformer_model": [32, 33, 34, 35, 36, 37, 38, 39, 40], "decod": 33, "decoderstack": 34, "encod": 35, "encoderstackold": 36, "transform": [37, 50, 53], "transformermodel": 38, "create_transform": 39, "get_transformer_model": 40, "trainer": [41, 42, 43, 44, 45], "transformer_train": [42, 43], "transformertrain": 43, "transformer_valid": [44, 45], "transformervalid": 45, "util": [46, 47, 48], "tf_util": [47, 48], "get_proc_devic": 48, "how": 50, "implement": 50, "sciform": 50, "ai": 50, "consult": 50, "quick": 50, "select": 50, "introduct": 51, "The": 52, "embed": 52, "what": 52, "ar": 52, "my": 52, "take": 52, "scale": 52, "type": 53}, "envversion": {"sphinx.domains.c": 3, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 9, "sphinx.domains.index": 1, "sphinx.domains.javascript": 3, "sphinx.domains.math": 2, "sphinx.domains.python": 4, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.intersphinx": 1, "sphinx.ext.viewcode": 1, "nbsphinx": 4, "sphinx": 60}, "alltitles": {"mt_transformer": [[0, "module-mt_transformer"]], "mt_transformer.config": [[1, "module-mt_transformer.config"]], "mt_transformer.config.project_config": [[2, "module-mt_transformer.config.project_config"]], "mt_transformer.config.project_config.Config": [[3, "mt-transformer-config-project-config-config"]], "mt_transformer.data_handler": [[4, "module-mt_transformer.data_handler"]], "mt_transformer.data_handler.data_loader": [[5, "module-mt_transformer.data_handler.data_loader"]], "mt_transformer.data_handler.data_loader.create_tokenizers_dataloaders": [[6, "mt-transformer-data-handler-data-loader-create-tokenizers-dataloaders"]], "mt_transformer.data_handler.data_loader.get_raw_data_opus_books": [[7, "mt-transformer-data-handler-data-loader-get-raw-data-opus-books"]], "mt_transformer.data_handler.data_tokenizer": [[8, "module-mt_transformer.data_handler.data_tokenizer"]], "mt_transformer.data_handler.data_tokenizer.check_max_seq_length": [[9, "mt-transformer-data-handler-data-tokenizer-check-max-seq-length"]], "mt_transformer.data_handler.data_tokenizer.get_all_text_sequences_from_dataset_in_language": [[10, "mt-transformer-data-handler-data-tokenizer-get-all-text-sequences-from-dataset-in-language"]], "mt_transformer.data_handler.data_tokenizer.get_or_create_tokenizer": [[11, "mt-transformer-data-handler-data-tokenizer-get-or-create-tokenizer"]], "mt_transformer.data_handler.masks": [[12, "module-mt_transformer.data_handler.masks"]], "mt_transformer.data_handler.masks.causal_mask": [[13, "mt-transformer-data-handler-masks-causal-mask"]], "mt_transformer.data_handler.two_language_data_set": [[14, "module-mt_transformer.data_handler.two_language_data_set"]], "mt_transformer.data_handler.two_language_data_set.TwoLanguagesDataset": [[15, "mt-transformer-data-handler-two-language-data-set-twolanguagesdataset"]], "mt_transformer.inference": [[16, "module-mt_transformer.inference"]], "mt_transformer.inference.tf_inference": [[17, "module-mt_transformer.inference.tf_inference"]], "mt_transformer.inference.tf_inference.TfInference": [[18, "mt-transformer-inference-tf-inference-tfinference"]], "mt_transformer.inference.tf_visualizer": [[19, "module-mt_transformer.inference.tf_visualizer"]], "mt_transformer.inference.tf_visualizer.TfVisualizer": [[20, "mt-transformer-inference-tf-visualizer-tfvisualizer"]], "mt_transformer.model": [[21, "module-mt_transformer.model"]], "mt_transformer.model.greedy_decoder": [[22, "module-mt_transformer.model.greedy_decoder"]], "mt_transformer.model.greedy_decoder.GreedyDecoder": [[23, "mt-transformer-model-greedy-decoder-greedydecoder"]], "mt_transformer.model.layers": [[24, "module-mt_transformer.model.layers"]], "mt_transformer.model.layers.FeedForwardBlock": [[25, "mt-transformer-model-layers-feedforwardblock"]], "mt_transformer.model.layers.LayerNormalization": [[26, "mt-transformer-model-layers-layernormalization"]], "mt_transformer.model.layers.MultiHeadAttention": [[27, "mt-transformer-model-layers-multiheadattention"]], "mt_transformer.model.layers.PositionalEncoding": [[28, "mt-transformer-model-layers-positionalencoding"]], "mt_transformer.model.layers.ProjectionLayer": [[29, "mt-transformer-model-layers-projectionlayer"]], "mt_transformer.model.layers.ResidualConnection": [[30, "mt-transformer-model-layers-residualconnection"]], "mt_transformer.model.layers.TokenEmbeddings": [[31, "mt-transformer-model-layers-tokenembeddings"]], "mt_transformer.model.transformer_model": [[32, "module-mt_transformer.model.transformer_model"]], "mt_transformer.model.transformer_model.Decoder": [[33, "mt-transformer-model-transformer-model-decoder"]], "mt_transformer.model.transformer_model.DecoderStack": [[34, "mt-transformer-model-transformer-model-decoderstack"]], "mt_transformer.model.transformer_model.Encoder": [[35, "mt-transformer-model-transformer-model-encoder"]], "mt_transformer.model.transformer_model.EncoderStackOld": [[36, "mt-transformer-model-transformer-model-encoderstackold"]], "mt_transformer.model.transformer_model.Transformer": [[37, "mt-transformer-model-transformer-model-transformer"]], "mt_transformer.model.transformer_model.TransformerModel": [[38, "mt-transformer-model-transformer-model-transformermodel"]], "mt_transformer.model.transformer_model.create_transformer": [[39, "mt-transformer-model-transformer-model-create-transformer"]], "mt_transformer.model.transformer_model.get_transformer_model": [[40, "mt-transformer-model-transformer-model-get-transformer-model"]], "mt_transformer.trainer": [[41, "module-mt_transformer.trainer"]], "mt_transformer.trainer.transformer_trainer": [[42, "module-mt_transformer.trainer.transformer_trainer"]], "mt_transformer.trainer.transformer_trainer.TransformerTrainer": [[43, "mt-transformer-trainer-transformer-trainer-transformertrainer"]], "mt_transformer.trainer.transformer_validator": [[44, "module-mt_transformer.trainer.transformer_validator"]], "mt_transformer.trainer.transformer_validator.TransformerValidator": [[45, "mt-transformer-trainer-transformer-validator-transformervalidator"]], "mt_transformer.utils": [[46, "module-mt_transformer.utils"]], "mt_transformer.utils.tf_utils": [[47, "module-mt_transformer.utils.tf_utils"]], "mt_transformer.utils.tf_utils.get_proc_device": [[48, "mt-transformer-utils-tf-utils-get-proc-device"]], "How to implement a Transformer ?": [[50, "how-to-implement-a-transformer"]], "Sciform - AI Consulting": [[50, "sciform-ai-consulting"]], "Quick Select": [[50, "quick-select"]], "Introduction": [[51, "introduction"]], "The Embeddings Layer": [[52, "the-embeddings-layer"]], "What are embeddings ?": [[52, "what-are-embeddings"]], "My take on scaling the embeddings": [[52, "my-take-on-scaling-the-embeddings"]], "Transformer": [[53, "transformer"]], "Layer Types": [[53, null]]}, "indexentries": {"module": [[0, "module-mt_transformer"], [1, "module-mt_transformer.config"], [2, "module-mt_transformer.config.project_config"], [4, "module-mt_transformer.data_handler"], [5, "module-mt_transformer.data_handler.data_loader"], [8, "module-mt_transformer.data_handler.data_tokenizer"], [12, "module-mt_transformer.data_handler.masks"], [14, "module-mt_transformer.data_handler.two_language_data_set"], [16, "module-mt_transformer.inference"], [17, "module-mt_transformer.inference.tf_inference"], [19, "module-mt_transformer.inference.tf_visualizer"], [21, "module-mt_transformer.model"], [22, "module-mt_transformer.model.greedy_decoder"], [24, "module-mt_transformer.model.layers"], [32, "module-mt_transformer.model.transformer_model"], [41, "module-mt_transformer.trainer"], [42, "module-mt_transformer.trainer.transformer_trainer"], [44, "module-mt_transformer.trainer.transformer_validator"], [46, "module-mt_transformer.utils"], [47, "module-mt_transformer.utils.tf_utils"]], "mt_transformer": [[0, "module-mt_transformer"]], "mt_transformer.config": [[1, "module-mt_transformer.config"]], "mt_transformer.config.project_config": [[2, "module-mt_transformer.config.project_config"]], "config (class in mt_transformer.config.project_config)": [[3, "mt_transformer.config.project_config.Config"]], "get_experiments_file_path() (config method)": [[3, "mt_transformer.config.project_config.Config.get_experiments_file_path"]], "get_rel_dictionary_file_path() (config method)": [[3, "mt_transformer.config.project_config.Config.get_rel_dictionary_file_path"]], "get_saved_model_file_path() (config method)": [[3, "mt_transformer.config.project_config.Config.get_saved_model_file_path"]], "mt_transformer.data_handler": [[4, "module-mt_transformer.data_handler"]], "mt_transformer.data_handler.data_loader": [[5, "module-mt_transformer.data_handler.data_loader"]], "create_tokenizers_dataloaders() (in module mt_transformer.data_handler.data_loader)": [[6, "mt_transformer.data_handler.data_loader.create_tokenizers_dataloaders"]], "get_raw_data_opus_books() (in module mt_transformer.data_handler.data_loader)": [[7, "mt_transformer.data_handler.data_loader.get_raw_data_opus_books"]], "mt_transformer.data_handler.data_tokenizer": [[8, "module-mt_transformer.data_handler.data_tokenizer"]], "check_max_seq_length() (in module mt_transformer.data_handler.data_tokenizer)": [[9, "mt_transformer.data_handler.data_tokenizer.check_max_seq_length"]], "get_all_text_sequences_from_dataset_in_language() (in module mt_transformer.data_handler.data_tokenizer)": [[10, "mt_transformer.data_handler.data_tokenizer.get_all_text_sequences_from_dataset_in_language"]], "get_or_create_tokenizer() (in module mt_transformer.data_handler.data_tokenizer)": [[11, "mt_transformer.data_handler.data_tokenizer.get_or_create_tokenizer"]], "mt_transformer.data_handler.masks": [[12, "module-mt_transformer.data_handler.masks"]], "causal_mask() (in module mt_transformer.data_handler.masks)": [[13, "mt_transformer.data_handler.masks.causal_mask"]], "mt_transformer.data_handler.two_language_data_set": [[14, "module-mt_transformer.data_handler.two_language_data_set"]], "twolanguagesdataset (class in mt_transformer.data_handler.two_language_data_set)": [[15, "mt_transformer.data_handler.two_language_data_set.TwoLanguagesDataset"]], "mt_transformer.inference": [[16, "module-mt_transformer.inference"]], "mt_transformer.inference.tf_inference": [[17, "module-mt_transformer.inference.tf_inference"]], "tfinference (class in mt_transformer.inference.tf_inference)": [[18, "mt_transformer.inference.tf_inference.TfInference"]], "mt_transformer.inference.tf_visualizer": [[19, "module-mt_transformer.inference.tf_visualizer"]], "tfvisualizer (class in mt_transformer.inference.tf_visualizer)": [[20, "mt_transformer.inference.tf_visualizer.TfVisualizer"]], "mt_transformer.model": [[21, "module-mt_transformer.model"]], "mt_transformer.model.greedy_decoder": [[22, "module-mt_transformer.model.greedy_decoder"]], "greedydecoder (class in mt_transformer.model.greedy_decoder)": [[23, "mt_transformer.model.greedy_decoder.GreedyDecoder"]], "mt_transformer.model.layers": [[24, "module-mt_transformer.model.layers"]], "feedforwardblock (class in mt_transformer.model.layers)": [[25, "mt_transformer.model.layers.FeedForwardBlock"]], "layernormalization (class in mt_transformer.model.layers)": [[26, "mt_transformer.model.layers.LayerNormalization"]], "multiheadattention (class in mt_transformer.model.layers)": [[27, "mt_transformer.model.layers.MultiHeadAttention"]], "positionalencoding (class in mt_transformer.model.layers)": [[28, "mt_transformer.model.layers.PositionalEncoding"]], "forward() (positionalencoding method)": [[28, "mt_transformer.model.layers.PositionalEncoding.forward"]], "projectionlayer (class in mt_transformer.model.layers)": [[29, "mt_transformer.model.layers.ProjectionLayer"]], "residualconnection (class in mt_transformer.model.layers)": [[30, "mt_transformer.model.layers.ResidualConnection"]], "tokenembeddings (class in mt_transformer.model.layers)": [[31, "mt_transformer.model.layers.TokenEmbeddings"]], "forward() (tokenembeddings method)": [[31, "mt_transformer.model.layers.TokenEmbeddings.forward"]], "mt_transformer.model.transformer_model": [[32, "module-mt_transformer.model.transformer_model"]], "decoder (class in mt_transformer.model.transformer_model)": [[33, "mt_transformer.model.transformer_model.Decoder"]], "decoderstack (class in mt_transformer.model.transformer_model)": [[34, "mt_transformer.model.transformer_model.DecoderStack"]], "forward() (decoderstack method)": [[34, "mt_transformer.model.transformer_model.DecoderStack.forward"]], "encoder (class in mt_transformer.model.transformer_model)": [[35, "mt_transformer.model.transformer_model.Encoder"]], "encoderstackold (class in mt_transformer.model.transformer_model)": [[36, "mt_transformer.model.transformer_model.EncoderStackOld"]], "forward() (encoderstackold method)": [[36, "mt_transformer.model.transformer_model.EncoderStackOld.forward"]], "transformer (class in mt_transformer.model.transformer_model)": [[37, "mt_transformer.model.transformer_model.Transformer"]], "transformermodel (class in mt_transformer.model.transformer_model)": [[38, "mt_transformer.model.transformer_model.TransformerModel"]], "create_transformer() (in module mt_transformer.model.transformer_model)": [[39, "mt_transformer.model.transformer_model.create_transformer"]], "get_transformer_model() (in module mt_transformer.model.transformer_model)": [[40, "mt_transformer.model.transformer_model.get_transformer_model"]], "mt_transformer.trainer": [[41, "module-mt_transformer.trainer"]], "mt_transformer.trainer.transformer_trainer": [[42, "module-mt_transformer.trainer.transformer_trainer"]], "transformertrainer (class in mt_transformer.trainer.transformer_trainer)": [[43, "mt_transformer.trainer.transformer_trainer.TransformerTrainer"]], "mt_transformer.trainer.transformer_validator": [[44, "module-mt_transformer.trainer.transformer_validator"]], "transformervalidator (class in mt_transformer.trainer.transformer_validator)": [[45, "mt_transformer.trainer.transformer_validator.TransformerValidator"]], "mt_transformer.utils": [[46, "module-mt_transformer.utils"]], "mt_transformer.utils.tf_utils": [[47, "module-mt_transformer.utils.tf_utils"]], "get_proc_device() (in module mt_transformer.utils.tf_utils)": [[48, "mt_transformer.utils.tf_utils.get_proc_device"]]}})