Search.setIndex({"docnames": ["_autosummary/mt_transformer", "_autosummary/mt_transformer.config", "_autosummary/mt_transformer.config.project_config", "_autosummary/mt_transformer.config.project_config.Config", "_autosummary/mt_transformer.data_handler", "_autosummary/mt_transformer.data_handler.data_loader", "_autosummary/mt_transformer.data_handler.data_loader.create_tokenizers_dataloaders", "_autosummary/mt_transformer.data_handler.data_loader.get_raw_data_opus_books", "_autosummary/mt_transformer.data_handler.data_tokenizer", "_autosummary/mt_transformer.data_handler.data_tokenizer.check_max_seq_length", "_autosummary/mt_transformer.data_handler.data_tokenizer.get_all_text_sequences_form_dataset_in_language", "_autosummary/mt_transformer.data_handler.data_tokenizer.get_or_create_tokenizer", "_autosummary/mt_transformer.data_handler.masks", "_autosummary/mt_transformer.data_handler.masks.causal_mask", "_autosummary/mt_transformer.data_handler.two_language_data_set", "_autosummary/mt_transformer.data_handler.two_language_data_set.TwoLanguagesDataset", "_autosummary/mt_transformer.model", "_autosummary/mt_transformer.model.greedy_decoder", "_autosummary/mt_transformer.model.greedy_decoder.GreedyDecoder", "_autosummary/mt_transformer.model.layers", "_autosummary/mt_transformer.model.layers.FeedForwardBlock", "_autosummary/mt_transformer.model.layers.LayerNormalization", "_autosummary/mt_transformer.model.layers.MultiHeadAttention", "_autosummary/mt_transformer.model.layers.PositionalEncoding", "_autosummary/mt_transformer.model.layers.ProjectionLayer", "_autosummary/mt_transformer.model.layers.ResidualConnection", "_autosummary/mt_transformer.model.layers.TokenEmbeddings", "_autosummary/mt_transformer.model.transformer_model", "_autosummary/mt_transformer.model.transformer_model.Decoder", "_autosummary/mt_transformer.model.transformer_model.DecoderStack", "_autosummary/mt_transformer.model.transformer_model.Encoder", "_autosummary/mt_transformer.model.transformer_model.EncoderStackOld", "_autosummary/mt_transformer.model.transformer_model.Transformer", "_autosummary/mt_transformer.model.transformer_model.TransformerModel", "_autosummary/mt_transformer.model.transformer_model.create_transformer", "_autosummary/mt_transformer.model.transformer_model.get_transformer_model", "_autosummary/mt_transformer.trainer", "_autosummary/mt_transformer.trainer.transformer_trainer", "_autosummary/mt_transformer.trainer.transformer_trainer.TransformerTrainer", "_autosummary/mt_transformer.trainer.transformer_validator", "_autosummary/mt_transformer.trainer.transformer_validator.TransformerValidator", "api", "index"], "filenames": ["_autosummary/mt_transformer.rst", "_autosummary/mt_transformer.config.rst", "_autosummary/mt_transformer.config.project_config.rst", "_autosummary/mt_transformer.config.project_config.Config.rst", "_autosummary/mt_transformer.data_handler.rst", "_autosummary/mt_transformer.data_handler.data_loader.rst", "_autosummary/mt_transformer.data_handler.data_loader.create_tokenizers_dataloaders.rst", "_autosummary/mt_transformer.data_handler.data_loader.get_raw_data_opus_books.rst", "_autosummary/mt_transformer.data_handler.data_tokenizer.rst", "_autosummary/mt_transformer.data_handler.data_tokenizer.check_max_seq_length.rst", "_autosummary/mt_transformer.data_handler.data_tokenizer.get_all_text_sequences_form_dataset_in_language.rst", "_autosummary/mt_transformer.data_handler.data_tokenizer.get_or_create_tokenizer.rst", "_autosummary/mt_transformer.data_handler.masks.rst", "_autosummary/mt_transformer.data_handler.masks.causal_mask.rst", "_autosummary/mt_transformer.data_handler.two_language_data_set.rst", "_autosummary/mt_transformer.data_handler.two_language_data_set.TwoLanguagesDataset.rst", "_autosummary/mt_transformer.model.rst", "_autosummary/mt_transformer.model.greedy_decoder.rst", "_autosummary/mt_transformer.model.greedy_decoder.GreedyDecoder.rst", "_autosummary/mt_transformer.model.layers.rst", "_autosummary/mt_transformer.model.layers.FeedForwardBlock.rst", "_autosummary/mt_transformer.model.layers.LayerNormalization.rst", "_autosummary/mt_transformer.model.layers.MultiHeadAttention.rst", "_autosummary/mt_transformer.model.layers.PositionalEncoding.rst", "_autosummary/mt_transformer.model.layers.ProjectionLayer.rst", "_autosummary/mt_transformer.model.layers.ResidualConnection.rst", "_autosummary/mt_transformer.model.layers.TokenEmbeddings.rst", "_autosummary/mt_transformer.model.transformer_model.rst", "_autosummary/mt_transformer.model.transformer_model.Decoder.rst", "_autosummary/mt_transformer.model.transformer_model.DecoderStack.rst", "_autosummary/mt_transformer.model.transformer_model.Encoder.rst", "_autosummary/mt_transformer.model.transformer_model.EncoderStackOld.rst", "_autosummary/mt_transformer.model.transformer_model.Transformer.rst", "_autosummary/mt_transformer.model.transformer_model.TransformerModel.rst", "_autosummary/mt_transformer.model.transformer_model.create_transformer.rst", "_autosummary/mt_transformer.model.transformer_model.get_transformer_model.rst", "_autosummary/mt_transformer.trainer.rst", "_autosummary/mt_transformer.trainer.transformer_trainer.rst", "_autosummary/mt_transformer.trainer.transformer_trainer.TransformerTrainer.rst", "_autosummary/mt_transformer.trainer.transformer_validator.rst", "_autosummary/mt_transformer.trainer.transformer_validator.TransformerValidator.rst", "api.rst", "index.rst"], "titles": ["mt_transformer", "mt_transformer.config", "mt_transformer.config.project_config", "mt_transformer.config.project_config.Config", "mt_transformer.data_handler", "mt_transformer.data_handler.data_loader", "mt_transformer.data_handler.data_loader.create_tokenizers_dataloaders", "mt_transformer.data_handler.data_loader.get_raw_data_opus_books", "mt_transformer.data_handler.data_tokenizer", "mt_transformer.data_handler.data_tokenizer.check_max_seq_length", "mt_transformer.data_handler.data_tokenizer.get_all_text_sequences_form_dataset_in_language", "mt_transformer.data_handler.data_tokenizer.get_or_create_tokenizer", "mt_transformer.data_handler.masks", "mt_transformer.data_handler.masks.causal_mask", "mt_transformer.data_handler.two_language_data_set", "mt_transformer.data_handler.two_language_data_set.TwoLanguagesDataset", "mt_transformer.model", "mt_transformer.model.greedy_decoder", "mt_transformer.model.greedy_decoder.GreedyDecoder", "mt_transformer.model.layers", "mt_transformer.model.layers.FeedForwardBlock", "mt_transformer.model.layers.LayerNormalization", "mt_transformer.model.layers.MultiHeadAttention", "mt_transformer.model.layers.PositionalEncoding", "mt_transformer.model.layers.ProjectionLayer", "mt_transformer.model.layers.ResidualConnection", "mt_transformer.model.layers.TokenEmbeddings", "mt_transformer.model.transformer_model", "mt_transformer.model.transformer_model.Decoder", "mt_transformer.model.transformer_model.DecoderStack", "mt_transformer.model.transformer_model.Encoder", "mt_transformer.model.transformer_model.EncoderStackOld", "mt_transformer.model.transformer_model.Transformer", "mt_transformer.model.transformer_model.TransformerModel", "mt_transformer.model.transformer_model.create_transformer", "mt_transformer.model.transformer_model.get_transformer_model", "mt_transformer.trainer", "mt_transformer.trainer.transformer_trainer", "mt_transformer.trainer.transformer_trainer.TransformerTrainer", "mt_transformer.trainer.transformer_validator", "mt_transformer.trainer.transformer_validator.TransformerValidator", "&lt;no title&gt;", "How to implement a transformer architecture from scratch ?"], "terms": {"document": [0, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "src": 0, "folder": 0, "class": [2, 3, 14, 15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 37, 38, 39, 40], "sourc": [3, 6, 7, 9, 10, 11, 13, 15, 18, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 38, 40], "base": [3, 15, 18, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 38, 40], "object": [3, 18, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 38, 40], "method": [3, 15, 18, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 38, 40], "function": [5, 8, 12, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33], "config": [6, 7, 11, 33, 35], "ds_raw": [9, 11], "token": [9, 11, 26, 31], "languag": [9, 10, 11], "lang_data_set": 10, "return": [11, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34], "type": [11, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34], "size": [13, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "d": 15, "tokenizer_src": 15, "tokenizer_tgt": 15, "src_lang": 15, "tgt_lang": 15, "seq_len": [15, 23], "dataset": 15, "d_model": [20, 22, 23, 24, 26, 34], "d_ff": [20, 33, 34], "dropout": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34], "modul": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "attribut": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "add_modul": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "name": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "add": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "child": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "current": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 42], "The": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 42], "can": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "access": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "an": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 42], "us": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "given": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "none": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "arg": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "str": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "from": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "thi": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 42], "ad": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "appli": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "fn": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "recurs": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "everi": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 42], "submodul": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "children": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "well": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "self": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "typic": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "includ": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "initi": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "paramet": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "see": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "also": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "nn": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "init": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "doc": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "typevar": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "t": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "bound": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "each": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "exampl": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "torch": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "no_grad": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "def": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "init_weight": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "m": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "print": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "linear": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "weight": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "fill_": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "1": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34], "0": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34], "net": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "sequenti": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "2": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "in_featur": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "out_featur": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "bia": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "true": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "contain": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "tensor": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "requires_grad": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "bfloat16": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "cast": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "all": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 42], "float": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "point": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "buffer": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "datatyp": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "rtype": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "modifi": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "place": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "iter": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "over": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "bool": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "yield": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "otherwis": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "onli": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "ar": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 42], "direct": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "member": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "xdoctest": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "skip": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "undefin": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "var": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "buf": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "20l": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "1l": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "5l": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "immedi": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "compil": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "kwarg": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "forward": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "__call__": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "i": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 42], "argument": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "pass": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "detail": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "cpu": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "move": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "cuda": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "devic": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "gpu": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "make": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "associ": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "differ": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "so": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "should": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "call": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "befor": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "construct": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "optim": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "live": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "while": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "being": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "int": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "option": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "specifi": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "copi": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "doubl": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "eval": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "set": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "evalu": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "mode": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "ha": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "ani": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "effect": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "certain": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "particular": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "behavior": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "train": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "thei": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "affect": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "e": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "g": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "batchnorm": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "etc": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "equival": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "fals": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "local": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "disabl": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "grad": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "comparison": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "between": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "sever": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "similar": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "mechan": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "mai": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "confus": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "extra_repr": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "extra": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "represent": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "To": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "custom": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "inform": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "you": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 42], "re": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "implement": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "your": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "own": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "both": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "singl": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "line": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "multi": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "string": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "accept": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "get_buff": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "target": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "exist": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "throw": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "error": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "docstr": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "get_submodul": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "more": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "explan": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "how": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "correctli": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "fulli": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "qualifi": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "look": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "referenc": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "rais": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "attributeerror": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "If": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "refer": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "invalid": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "path": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "resolv": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "someth": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "get_extra_st": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "state": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 42], "state_dict": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "correspond": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "set_extra_st": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "need": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 42], "store": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "when": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 42], "build": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "note": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "picklabl": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "ensur": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "work": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "serial": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "we": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 42], "provid": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 42], "backward": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "compat": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "guarante": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "other": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "break": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "pickl": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "form": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "chang": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "get_paramet": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "For": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "let": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 42], "sai": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "have": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "A": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 42], "like": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "net_b": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "net_c": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "conv": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "conv2d": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "16": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "33": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "kernel_s": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "3": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "stride": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "100": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "200": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "diagram": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "show": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "nest": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "which": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "itself": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "two": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "check": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "whether": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "would": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "runtim": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "degre": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "queri": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "against": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "named_modul": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "achiev": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "same": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "result": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "o": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "n": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "number": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "transit": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "simpl": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "some": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "alwai": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "abov": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "half": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "ipu": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "load_state_dict": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "strict": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "assign": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "its": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "descend": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "kei": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "must": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "exactli": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "match": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "creat": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "after": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "dict": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "persist": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "strictli": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "enforc": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "default": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "item": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "dictionari": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "instead": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "them": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "inplac": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "properti": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "preserv": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "namedtupl": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "missing_kei": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "unexpected_kei": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "field": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "list": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "miss": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "unexpect": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "regist": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "runtimeerror": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "network": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "duplic": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "onc": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "In": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "follow": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "l": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "idx": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "enumer": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "named_buff": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "prefix": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "remove_dupl": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "tupl": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "prepend": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "remov": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "running_var": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "named_children": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "conv4": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "conv5": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "memo": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "alreadi": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "instanc": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "named_paramet": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "param": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "register_backward_hook": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "hook": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "deprec": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "favor": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "register_full_backward_hook": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "futur": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "version": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "removablehandl": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "util": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "handl": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "register_buff": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "consid": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "running_mean": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "part": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "save": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "alongsid": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "non": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "latter": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "oper": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "run": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "ignor": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "zero": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "num_featur": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "register_forward_hook": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "with_kwarg": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "always_cal": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "time": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "comput": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "output": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "input": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "posit": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "keyword": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "won": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "It": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "sinc": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "signatur": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "expect": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "possibli": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "callabl": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "user": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "defin": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "fire": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "global": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "register_module_forward_hook": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "regardless": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "except": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "register_forward_pre_hook": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "pre": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "invok": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "either": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "valu": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "wrap": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "unless": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "And": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "forward_pr": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "register_module_forward_pre_hook": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "gradient": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "respect": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "execut": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "grad_input": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "grad_output": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "new": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "subsequ": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "entri": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "technic": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "reason": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "receiv": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "view": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "similarli": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "caller": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "allow": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "register_module_full_backward_hook": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "register_full_backward_pre_hook": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "backward_pr": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "register_module_full_backward_pre_hook": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "register_load_state_dict_post_hook": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "post": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "incompatible_kei": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "consist": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "perform": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "modif": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "addit": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "thrown": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "clear": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "out": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "avoid": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "register_modul": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "alia": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "register_paramet": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "register_state_dict_pre_hook": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "These": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "keep_var": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "process": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "made": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "requires_grad_": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "autograd": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "record": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "help": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "freez": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "finetun": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "individu": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "gan": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "found": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "within": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "share_memori": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "share_memory_": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "destin": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "whole": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "averag": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "shallow": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "order": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "howev": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "releas": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "pleas": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "design": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "end": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "updat": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "ordereddict": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "compos": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "detach": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "dtype": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "non_block": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "memory_format": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "channels_last": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "Its": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "complex": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "integr": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "unchang": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "tri": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "convert": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "asynchron": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "host": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "possibl": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "pin": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "memori": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "below": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "desir": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "whose": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "format": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "4d": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "ignore_w": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "determinist": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "1913": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "3420": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "5113": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "2325": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "float64": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "requir": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "env": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "torch_doctest_cuda1": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "gpu1": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "1914": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "5112": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "2324": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "float16": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "cdoubl": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "3741": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "j": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "2382": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "5593": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "4443": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "complex128": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "ones": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "6122": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "1150": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "to_empti": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "without": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "storag": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "dst_type": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "xpu": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "zero_grad": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "set_to_non": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "reset": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "under": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 42], "context": [20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "ep": 21, "1e": 21, "06": 21, "http": [21, 26, 42], "www": 21, "pinecon": 21, "io": 21, "learn": [21, 23, 26, 42], "batch": [21, 23, 26], "normal": [21, 25], "num_head": 22, "drop_out": 23, "x": [23, 26, 29, 31], "encod": [23, 26, 32], "previou": [23, 25], "usual": 23, "shape": 23, "dim": [23, 26], "tell": 23, "precomput": 23, "drop": 23, "sum": 23, "vocab_s": 24, "first": 25, "sublay": 25, "norm": 25, "vice": 25, "versa": 25, "dictionary_s": 26, "embed": 26, "featur": 26, "fix": 26, "sequenc": 26, "map": 26, "num_batch": 26, "sequence_length": 26, "multipli": 26, "sqrt": 26, "scale": 26, "origin": [26, 42], "paper": 26, "doe": 26, "explain": 26, "why": 26, "datasci": 26, "stackexchang": 26, "com": 26, "question": 26, "87906": 26, "transform": [26, 34], "word": 26, "layer": [28, 30], "self_attention_block": [29, 31], "cross_attention_block": 29, "feed_forward_block": [29, 31], "encoder_output": 29, "src_mask": [29, 31], "tgt_mask": 29, "establish": 29, "causal": 29, "mask": 31, "actual": 31, "interact": 31, "pad": 31, "decod": 32, "src_emb": 32, "tgt_emb": 32, "src_po": 32, "tgt_po": 32, "projection_lay": 32, "overridden": [32, 33], "subclass": [32, 33], "although": [32, 33], "recip": [32, 33], "one": [32, 33], "afterward": [32, 33], "former": [32, 33], "take": [32, 33], "care": [32, 33], "silent": [32, 33], "num_stack": [33, 34], "6": [33, 34], "h": [33, 34], "8": [33, 34], "2048": [33, 34], "src_vocab_s": 34, "tgt_vocab_s": 34, "src_seq_len": 34, "tgt_seq_len": 34, "512": 34, "vocab_src_len": 35, "vocab_tgt_len": 35, "project": 42, "activ": 42, "develop": 42, "stai": 42, "tune": 42, "know": 42, "readi": 42, "power": 42, "almost": 42, "art": 42, "deep": 42, "model": 42, "here": 42, "publish": 42, "vaswani": 42, "et": 42, "al": 42, "2017": 42, "attent": 42, "arxiv": 42, "org": 42, "ab": 42, "1706": 42, "03762": 42}, "objects": {"": [[0, 0, 0, "-", "mt_transformer"]], "mt_transformer": [[1, 0, 0, "-", "config"], [4, 0, 0, "-", "data_handler"], [16, 0, 0, "-", "model"], [36, 0, 0, "-", "trainer"]], "mt_transformer.config": [[2, 0, 0, "-", "project_config"]], "mt_transformer.config.project_config": [[3, 1, 1, "", "Config"]], "mt_transformer.data_handler": [[5, 0, 0, "-", "data_loader"], [8, 0, 0, "-", "data_tokenizer"], [12, 0, 0, "-", "masks"], [14, 0, 0, "-", "two_language_data_set"]], "mt_transformer.data_handler.data_loader": [[6, 2, 1, "", "create_tokenizers_dataloaders"], [7, 2, 1, "", "get_raw_data_opus_books"]], "mt_transformer.data_handler.data_tokenizer": [[9, 2, 1, "", "check_max_seq_length"], [10, 2, 1, "", "get_all_text_sequences_form_dataset_in_language"], [11, 2, 1, "", "get_or_create_tokenizer"]], "mt_transformer.data_handler.masks": [[13, 2, 1, "", "causal_mask"]], "mt_transformer.data_handler.two_language_data_set": [[15, 1, 1, "", "TwoLanguagesDataset"]], "mt_transformer.model": [[17, 0, 0, "-", "greedy_decoder"], [19, 0, 0, "-", "layers"], [27, 0, 0, "-", "transformer_model"]], "mt_transformer.model.greedy_decoder": [[18, 1, 1, "", "GreedyDecoder"]], "mt_transformer.model.layers": [[20, 1, 1, "", "FeedForwardBlock"], [21, 1, 1, "", "LayerNormalization"], [22, 1, 1, "", "MultiHeadAttention"], [23, 1, 1, "", "PositionalEncoding"], [24, 1, 1, "", "ProjectionLayer"], [25, 1, 1, "", "ResidualConnection"], [26, 1, 1, "", "TokenEmbeddings"]], "mt_transformer.model.layers.FeedForwardBlock": [[20, 3, 1, "", "add_module"], [20, 3, 1, "", "apply"], [20, 3, 1, "", "bfloat16"], [20, 3, 1, "", "buffers"], [20, 3, 1, "", "children"], [20, 3, 1, "", "compile"], [20, 3, 1, "", "cpu"], [20, 3, 1, "", "cuda"], [20, 3, 1, "", "double"], [20, 3, 1, "", "eval"], [20, 3, 1, "", "extra_repr"], [20, 3, 1, "", "float"], [20, 3, 1, "", "get_buffer"], [20, 3, 1, "", "get_extra_state"], [20, 3, 1, "", "get_parameter"], [20, 3, 1, "", "get_submodule"], [20, 3, 1, "", "half"], [20, 3, 1, "", "ipu"], [20, 3, 1, "", "load_state_dict"], [20, 3, 1, "", "modules"], [20, 3, 1, "", "named_buffers"], [20, 3, 1, "", "named_children"], [20, 3, 1, "", "named_modules"], [20, 3, 1, "", "named_parameters"], [20, 3, 1, "", "parameters"], [20, 3, 1, "", "register_backward_hook"], [20, 3, 1, "", "register_buffer"], [20, 3, 1, "", "register_forward_hook"], [20, 3, 1, "", "register_forward_pre_hook"], [20, 3, 1, "", "register_full_backward_hook"], [20, 3, 1, "", "register_full_backward_pre_hook"], [20, 3, 1, "", "register_load_state_dict_post_hook"], [20, 3, 1, "", "register_module"], [20, 3, 1, "", "register_parameter"], [20, 3, 1, "", "register_state_dict_pre_hook"], [20, 3, 1, "", "requires_grad_"], [20, 3, 1, "", "set_extra_state"], [20, 3, 1, "", "share_memory"], [20, 3, 1, "", "state_dict"], [20, 3, 1, "", "to"], [20, 3, 1, "", "to_empty"], [20, 3, 1, "", "train"], [20, 3, 1, "", "type"], [20, 3, 1, "", "xpu"], [20, 3, 1, "", "zero_grad"]], "mt_transformer.model.layers.LayerNormalization": [[21, 3, 1, "", "add_module"], [21, 3, 1, "", "apply"], [21, 3, 1, "", "bfloat16"], [21, 3, 1, "", "buffers"], [21, 3, 1, "", "children"], [21, 3, 1, "", "compile"], [21, 3, 1, "", "cpu"], [21, 3, 1, "", "cuda"], [21, 3, 1, "", "double"], [21, 3, 1, "", "eval"], [21, 3, 1, "", "extra_repr"], [21, 3, 1, "", "float"], [21, 3, 1, "", "get_buffer"], [21, 3, 1, "", "get_extra_state"], [21, 3, 1, "", "get_parameter"], [21, 3, 1, "", "get_submodule"], [21, 3, 1, "", "half"], [21, 3, 1, "", "ipu"], [21, 3, 1, "", "load_state_dict"], [21, 3, 1, "", "modules"], [21, 3, 1, "", "named_buffers"], [21, 3, 1, "", "named_children"], [21, 3, 1, "", "named_modules"], [21, 3, 1, "", "named_parameters"], [21, 3, 1, "", "parameters"], [21, 3, 1, "", "register_backward_hook"], [21, 3, 1, "", "register_buffer"], [21, 3, 1, "", "register_forward_hook"], [21, 3, 1, "", "register_forward_pre_hook"], [21, 3, 1, "", "register_full_backward_hook"], [21, 3, 1, "", "register_full_backward_pre_hook"], [21, 3, 1, "", "register_load_state_dict_post_hook"], [21, 3, 1, "", "register_module"], [21, 3, 1, "", "register_parameter"], [21, 3, 1, "", "register_state_dict_pre_hook"], [21, 3, 1, "", "requires_grad_"], [21, 3, 1, "", "set_extra_state"], [21, 3, 1, "", "share_memory"], [21, 3, 1, "", "state_dict"], [21, 3, 1, "", "to"], [21, 3, 1, "", "to_empty"], [21, 3, 1, "", "train"], [21, 3, 1, "", "type"], [21, 3, 1, "", "xpu"], [21, 3, 1, "", "zero_grad"]], "mt_transformer.model.layers.MultiHeadAttention": [[22, 3, 1, "", "add_module"], [22, 3, 1, "", "apply"], [22, 3, 1, "", "bfloat16"], [22, 3, 1, "", "buffers"], [22, 3, 1, "", "children"], [22, 3, 1, "", "compile"], [22, 3, 1, "", "cpu"], [22, 3, 1, "", "cuda"], [22, 3, 1, "", "double"], [22, 3, 1, "", "eval"], [22, 3, 1, "", "extra_repr"], [22, 3, 1, "", "float"], [22, 3, 1, "", "get_buffer"], [22, 3, 1, "", "get_extra_state"], [22, 3, 1, "", "get_parameter"], [22, 3, 1, "", "get_submodule"], [22, 3, 1, "", "half"], [22, 3, 1, "", "ipu"], [22, 3, 1, "", "load_state_dict"], [22, 3, 1, "", "modules"], [22, 3, 1, "", "named_buffers"], [22, 3, 1, "", "named_children"], [22, 3, 1, "", "named_modules"], [22, 3, 1, "", "named_parameters"], [22, 3, 1, "", "parameters"], [22, 3, 1, "", "register_backward_hook"], [22, 3, 1, "", "register_buffer"], [22, 3, 1, "", "register_forward_hook"], [22, 3, 1, "", "register_forward_pre_hook"], [22, 3, 1, "", "register_full_backward_hook"], [22, 3, 1, "", "register_full_backward_pre_hook"], [22, 3, 1, "", "register_load_state_dict_post_hook"], [22, 3, 1, "", "register_module"], [22, 3, 1, "", "register_parameter"], [22, 3, 1, "", "register_state_dict_pre_hook"], [22, 3, 1, "", "requires_grad_"], [22, 3, 1, "", "set_extra_state"], [22, 3, 1, "", "share_memory"], [22, 3, 1, "", "state_dict"], [22, 3, 1, "", "to"], [22, 3, 1, "", "to_empty"], [22, 3, 1, "", "train"], [22, 3, 1, "", "type"], [22, 3, 1, "", "xpu"], [22, 3, 1, "", "zero_grad"]], "mt_transformer.model.layers.PositionalEncoding": [[23, 3, 1, "", "add_module"], [23, 3, 1, "", "apply"], [23, 3, 1, "", "bfloat16"], [23, 3, 1, "", "buffers"], [23, 3, 1, "", "children"], [23, 3, 1, "", "compile"], [23, 3, 1, "", "cpu"], [23, 3, 1, "", "cuda"], [23, 3, 1, "", "double"], [23, 3, 1, "", "eval"], [23, 3, 1, "", "extra_repr"], [23, 3, 1, "", "float"], [23, 3, 1, "", "forward"], [23, 3, 1, "", "get_buffer"], [23, 3, 1, "", "get_extra_state"], [23, 3, 1, "", "get_parameter"], [23, 3, 1, "", "get_submodule"], [23, 3, 1, "", "half"], [23, 3, 1, "", "ipu"], [23, 3, 1, "", "load_state_dict"], [23, 3, 1, "", "modules"], [23, 3, 1, "", "named_buffers"], [23, 3, 1, "", "named_children"], [23, 3, 1, "", "named_modules"], [23, 3, 1, "", "named_parameters"], [23, 3, 1, "", "parameters"], [23, 3, 1, "", "register_backward_hook"], [23, 3, 1, "", "register_buffer"], [23, 3, 1, "", "register_forward_hook"], [23, 3, 1, "", "register_forward_pre_hook"], [23, 3, 1, "", "register_full_backward_hook"], [23, 3, 1, "", "register_full_backward_pre_hook"], [23, 3, 1, "", "register_load_state_dict_post_hook"], [23, 3, 1, "", "register_module"], [23, 3, 1, "", "register_parameter"], [23, 3, 1, "", "register_state_dict_pre_hook"], [23, 3, 1, "", "requires_grad_"], [23, 3, 1, "", "set_extra_state"], [23, 3, 1, "", "share_memory"], [23, 3, 1, "", "state_dict"], [23, 3, 1, "", "to"], [23, 3, 1, "", "to_empty"], [23, 3, 1, "", "train"], [23, 3, 1, "", "type"], [23, 3, 1, "", "xpu"], [23, 3, 1, "", "zero_grad"]], "mt_transformer.model.layers.ProjectionLayer": [[24, 3, 1, "", "add_module"], [24, 3, 1, "", "apply"], [24, 3, 1, "", "bfloat16"], [24, 3, 1, "", "buffers"], [24, 3, 1, "", "children"], [24, 3, 1, "", "compile"], [24, 3, 1, "", "cpu"], [24, 3, 1, "", "cuda"], [24, 3, 1, "", "double"], [24, 3, 1, "", "eval"], [24, 3, 1, "", "extra_repr"], [24, 3, 1, "", "float"], [24, 3, 1, "", "get_buffer"], [24, 3, 1, "", "get_extra_state"], [24, 3, 1, "", "get_parameter"], [24, 3, 1, "", "get_submodule"], [24, 3, 1, "", "half"], [24, 3, 1, "", "ipu"], [24, 3, 1, "", "load_state_dict"], [24, 3, 1, "", "modules"], [24, 3, 1, "", "named_buffers"], [24, 3, 1, "", "named_children"], [24, 3, 1, "", "named_modules"], [24, 3, 1, "", "named_parameters"], [24, 3, 1, "", "parameters"], [24, 3, 1, "", "register_backward_hook"], [24, 3, 1, "", "register_buffer"], [24, 3, 1, "", "register_forward_hook"], [24, 3, 1, "", "register_forward_pre_hook"], [24, 3, 1, "", "register_full_backward_hook"], [24, 3, 1, "", "register_full_backward_pre_hook"], [24, 3, 1, "", "register_load_state_dict_post_hook"], [24, 3, 1, "", "register_module"], [24, 3, 1, "", "register_parameter"], [24, 3, 1, "", "register_state_dict_pre_hook"], [24, 3, 1, "", "requires_grad_"], [24, 3, 1, "", "set_extra_state"], [24, 3, 1, "", "share_memory"], [24, 3, 1, "", "state_dict"], [24, 3, 1, "", "to"], [24, 3, 1, "", "to_empty"], [24, 3, 1, "", "train"], [24, 3, 1, "", "type"], [24, 3, 1, "", "xpu"], [24, 3, 1, "", "zero_grad"]], "mt_transformer.model.layers.ResidualConnection": [[25, 3, 1, "", "add_module"], [25, 3, 1, "", "apply"], [25, 3, 1, "", "bfloat16"], [25, 3, 1, "", "buffers"], [25, 3, 1, "", "children"], [25, 3, 1, "", "compile"], [25, 3, 1, "", "cpu"], [25, 3, 1, "", "cuda"], [25, 3, 1, "", "double"], [25, 3, 1, "", "eval"], [25, 3, 1, "", "extra_repr"], [25, 3, 1, "", "float"], [25, 3, 1, "", "get_buffer"], [25, 3, 1, "", "get_extra_state"], [25, 3, 1, "", "get_parameter"], [25, 3, 1, "", "get_submodule"], [25, 3, 1, "", "half"], [25, 3, 1, "", "ipu"], [25, 3, 1, "", "load_state_dict"], [25, 3, 1, "", "modules"], [25, 3, 1, "", "named_buffers"], [25, 3, 1, "", "named_children"], [25, 3, 1, "", "named_modules"], [25, 3, 1, "", "named_parameters"], [25, 3, 1, "", "parameters"], [25, 3, 1, "", "register_backward_hook"], [25, 3, 1, "", "register_buffer"], [25, 3, 1, "", "register_forward_hook"], [25, 3, 1, "", "register_forward_pre_hook"], [25, 3, 1, "", "register_full_backward_hook"], [25, 3, 1, "", "register_full_backward_pre_hook"], [25, 3, 1, "", "register_load_state_dict_post_hook"], [25, 3, 1, "", "register_module"], [25, 3, 1, "", "register_parameter"], [25, 3, 1, "", "register_state_dict_pre_hook"], [25, 3, 1, "", "requires_grad_"], [25, 3, 1, "", "set_extra_state"], [25, 3, 1, "", "share_memory"], [25, 3, 1, "", "state_dict"], [25, 3, 1, "", "to"], [25, 3, 1, "", "to_empty"], [25, 3, 1, "", "train"], [25, 3, 1, "", "type"], [25, 3, 1, "", "xpu"], [25, 3, 1, "", "zero_grad"]], "mt_transformer.model.layers.TokenEmbeddings": [[26, 3, 1, "", "add_module"], [26, 3, 1, "", "apply"], [26, 3, 1, "", "bfloat16"], [26, 3, 1, "", "buffers"], [26, 3, 1, "", "children"], [26, 3, 1, "", "compile"], [26, 3, 1, "", "cpu"], [26, 3, 1, "", "cuda"], [26, 3, 1, "", "double"], [26, 3, 1, "", "eval"], [26, 3, 1, "", "extra_repr"], [26, 3, 1, "", "float"], [26, 3, 1, "", "forward"], [26, 3, 1, "", "get_buffer"], [26, 3, 1, "", "get_extra_state"], [26, 3, 1, "", "get_parameter"], [26, 3, 1, "", "get_submodule"], [26, 3, 1, "", "half"], [26, 3, 1, "", "ipu"], [26, 3, 1, "", "load_state_dict"], [26, 3, 1, "", "modules"], [26, 3, 1, "", "named_buffers"], [26, 3, 1, "", "named_children"], [26, 3, 1, "", "named_modules"], [26, 3, 1, "", "named_parameters"], [26, 3, 1, "", "parameters"], [26, 3, 1, "", "register_backward_hook"], [26, 3, 1, "", "register_buffer"], [26, 3, 1, "", "register_forward_hook"], [26, 3, 1, "", "register_forward_pre_hook"], [26, 3, 1, "", "register_full_backward_hook"], [26, 3, 1, "", "register_full_backward_pre_hook"], [26, 3, 1, "", "register_load_state_dict_post_hook"], [26, 3, 1, "", "register_module"], [26, 3, 1, "", "register_parameter"], [26, 3, 1, "", "register_state_dict_pre_hook"], [26, 3, 1, "", "requires_grad_"], [26, 3, 1, "", "set_extra_state"], [26, 3, 1, "", "share_memory"], [26, 3, 1, "", "state_dict"], [26, 3, 1, "", "to"], [26, 3, 1, "", "to_empty"], [26, 3, 1, "", "train"], [26, 3, 1, "", "type"], [26, 3, 1, "", "xpu"], [26, 3, 1, "", "zero_grad"]], "mt_transformer.model.transformer_model": [[28, 1, 1, "", "Decoder"], [29, 1, 1, "", "DecoderStack"], [30, 1, 1, "", "Encoder"], [31, 1, 1, "", "EncoderStackOld"], [32, 1, 1, "", "Transformer"], [33, 1, 1, "", "TransformerModel"], [34, 2, 1, "", "create_transformer"], [35, 2, 1, "", "get_transformer_model"]], "mt_transformer.model.transformer_model.Decoder": [[28, 3, 1, "", "add_module"], [28, 3, 1, "", "apply"], [28, 3, 1, "", "bfloat16"], [28, 3, 1, "", "buffers"], [28, 3, 1, "", "children"], [28, 3, 1, "", "compile"], [28, 3, 1, "", "cpu"], [28, 3, 1, "", "cuda"], [28, 3, 1, "", "double"], [28, 3, 1, "", "eval"], [28, 3, 1, "", "extra_repr"], [28, 3, 1, "", "float"], [28, 3, 1, "", "get_buffer"], [28, 3, 1, "", "get_extra_state"], [28, 3, 1, "", "get_parameter"], [28, 3, 1, "", "get_submodule"], [28, 3, 1, "", "half"], [28, 3, 1, "", "ipu"], [28, 3, 1, "", "load_state_dict"], [28, 3, 1, "", "modules"], [28, 3, 1, "", "named_buffers"], [28, 3, 1, "", "named_children"], [28, 3, 1, "", "named_modules"], [28, 3, 1, "", "named_parameters"], [28, 3, 1, "", "parameters"], [28, 3, 1, "", "register_backward_hook"], [28, 3, 1, "", "register_buffer"], [28, 3, 1, "", "register_forward_hook"], [28, 3, 1, "", "register_forward_pre_hook"], [28, 3, 1, "", "register_full_backward_hook"], [28, 3, 1, "", "register_full_backward_pre_hook"], [28, 3, 1, "", "register_load_state_dict_post_hook"], [28, 3, 1, "", "register_module"], [28, 3, 1, "", "register_parameter"], [28, 3, 1, "", "register_state_dict_pre_hook"], [28, 3, 1, "", "requires_grad_"], [28, 3, 1, "", "set_extra_state"], [28, 3, 1, "", "share_memory"], [28, 3, 1, "", "state_dict"], [28, 3, 1, "", "to"], [28, 3, 1, "", "to_empty"], [28, 3, 1, "", "train"], [28, 3, 1, "", "type"], [28, 3, 1, "", "xpu"], [28, 3, 1, "", "zero_grad"]], "mt_transformer.model.transformer_model.DecoderStack": [[29, 3, 1, "", "add_module"], [29, 3, 1, "", "apply"], [29, 3, 1, "", "bfloat16"], [29, 3, 1, "", "buffers"], [29, 3, 1, "", "children"], [29, 3, 1, "", "compile"], [29, 3, 1, "", "cpu"], [29, 3, 1, "", "cuda"], [29, 3, 1, "", "double"], [29, 3, 1, "", "eval"], [29, 3, 1, "", "extra_repr"], [29, 3, 1, "", "float"], [29, 3, 1, "", "forward"], [29, 3, 1, "", "get_buffer"], [29, 3, 1, "", "get_extra_state"], [29, 3, 1, "", "get_parameter"], [29, 3, 1, "", "get_submodule"], [29, 3, 1, "", "half"], [29, 3, 1, "", "ipu"], [29, 3, 1, "", "load_state_dict"], [29, 3, 1, "", "modules"], [29, 3, 1, "", "named_buffers"], [29, 3, 1, "", "named_children"], [29, 3, 1, "", "named_modules"], [29, 3, 1, "", "named_parameters"], [29, 3, 1, "", "parameters"], [29, 3, 1, "", "register_backward_hook"], [29, 3, 1, "", "register_buffer"], [29, 3, 1, "", "register_forward_hook"], [29, 3, 1, "", "register_forward_pre_hook"], [29, 3, 1, "", "register_full_backward_hook"], [29, 3, 1, "", "register_full_backward_pre_hook"], [29, 3, 1, "", "register_load_state_dict_post_hook"], [29, 3, 1, "", "register_module"], [29, 3, 1, "", "register_parameter"], [29, 3, 1, "", "register_state_dict_pre_hook"], [29, 3, 1, "", "requires_grad_"], [29, 3, 1, "", "set_extra_state"], [29, 3, 1, "", "share_memory"], [29, 3, 1, "", "state_dict"], [29, 3, 1, "", "to"], [29, 3, 1, "", "to_empty"], [29, 3, 1, "", "train"], [29, 3, 1, "", "type"], [29, 3, 1, "", "xpu"], [29, 3, 1, "", "zero_grad"]], "mt_transformer.model.transformer_model.Encoder": [[30, 3, 1, "", "add_module"], [30, 3, 1, "", "apply"], [30, 3, 1, "", "bfloat16"], [30, 3, 1, "", "buffers"], [30, 3, 1, "", "children"], [30, 3, 1, "", "compile"], [30, 3, 1, "", "cpu"], [30, 3, 1, "", "cuda"], [30, 3, 1, "", "double"], [30, 3, 1, "", "eval"], [30, 3, 1, "", "extra_repr"], [30, 3, 1, "", "float"], [30, 3, 1, "", "get_buffer"], [30, 3, 1, "", "get_extra_state"], [30, 3, 1, "", "get_parameter"], [30, 3, 1, "", "get_submodule"], [30, 3, 1, "", "half"], [30, 3, 1, "", "ipu"], [30, 3, 1, "", "load_state_dict"], [30, 3, 1, "", "modules"], [30, 3, 1, "", "named_buffers"], [30, 3, 1, "", "named_children"], [30, 3, 1, "", "named_modules"], [30, 3, 1, "", "named_parameters"], [30, 3, 1, "", "parameters"], [30, 3, 1, "", "register_backward_hook"], [30, 3, 1, "", "register_buffer"], [30, 3, 1, "", "register_forward_hook"], [30, 3, 1, "", "register_forward_pre_hook"], [30, 3, 1, "", "register_full_backward_hook"], [30, 3, 1, "", "register_full_backward_pre_hook"], [30, 3, 1, "", "register_load_state_dict_post_hook"], [30, 3, 1, "", "register_module"], [30, 3, 1, "", "register_parameter"], [30, 3, 1, "", "register_state_dict_pre_hook"], [30, 3, 1, "", "requires_grad_"], [30, 3, 1, "", "set_extra_state"], [30, 3, 1, "", "share_memory"], [30, 3, 1, "", "state_dict"], [30, 3, 1, "", "to"], [30, 3, 1, "", "to_empty"], [30, 3, 1, "", "train"], [30, 3, 1, "", "type"], [30, 3, 1, "", "xpu"], [30, 3, 1, "", "zero_grad"]], "mt_transformer.model.transformer_model.EncoderStackOld": [[31, 3, 1, "", "add_module"], [31, 3, 1, "", "apply"], [31, 3, 1, "", "bfloat16"], [31, 3, 1, "", "buffers"], [31, 3, 1, "", "children"], [31, 3, 1, "", "compile"], [31, 3, 1, "", "cpu"], [31, 3, 1, "", "cuda"], [31, 3, 1, "", "double"], [31, 3, 1, "", "eval"], [31, 3, 1, "", "extra_repr"], [31, 3, 1, "", "float"], [31, 3, 1, "", "forward"], [31, 3, 1, "", "get_buffer"], [31, 3, 1, "", "get_extra_state"], [31, 3, 1, "", "get_parameter"], [31, 3, 1, "", "get_submodule"], [31, 3, 1, "", "half"], [31, 3, 1, "", "ipu"], [31, 3, 1, "", "load_state_dict"], [31, 3, 1, "", "modules"], [31, 3, 1, "", "named_buffers"], [31, 3, 1, "", "named_children"], [31, 3, 1, "", "named_modules"], [31, 3, 1, "", "named_parameters"], [31, 3, 1, "", "parameters"], [31, 3, 1, "", "register_backward_hook"], [31, 3, 1, "", "register_buffer"], [31, 3, 1, "", "register_forward_hook"], [31, 3, 1, "", "register_forward_pre_hook"], [31, 3, 1, "", "register_full_backward_hook"], [31, 3, 1, "", "register_full_backward_pre_hook"], [31, 3, 1, "", "register_load_state_dict_post_hook"], [31, 3, 1, "", "register_module"], [31, 3, 1, "", "register_parameter"], [31, 3, 1, "", "register_state_dict_pre_hook"], [31, 3, 1, "", "requires_grad_"], [31, 3, 1, "", "set_extra_state"], [31, 3, 1, "", "share_memory"], [31, 3, 1, "", "state_dict"], [31, 3, 1, "", "to"], [31, 3, 1, "", "to_empty"], [31, 3, 1, "", "train"], [31, 3, 1, "", "type"], [31, 3, 1, "", "xpu"], [31, 3, 1, "", "zero_grad"]], "mt_transformer.model.transformer_model.Transformer": [[32, 3, 1, "", "add_module"], [32, 3, 1, "", "apply"], [32, 3, 1, "", "bfloat16"], [32, 3, 1, "", "buffers"], [32, 3, 1, "", "children"], [32, 3, 1, "", "compile"], [32, 3, 1, "", "cpu"], [32, 3, 1, "", "cuda"], [32, 3, 1, "", "double"], [32, 3, 1, "", "eval"], [32, 3, 1, "", "extra_repr"], [32, 3, 1, "", "float"], [32, 3, 1, "", "forward"], [32, 3, 1, "", "get_buffer"], [32, 3, 1, "", "get_extra_state"], [32, 3, 1, "", "get_parameter"], [32, 3, 1, "", "get_submodule"], [32, 3, 1, "", "half"], [32, 3, 1, "", "ipu"], [32, 3, 1, "", "load_state_dict"], [32, 3, 1, "", "modules"], [32, 3, 1, "", "named_buffers"], [32, 3, 1, "", "named_children"], [32, 3, 1, "", "named_modules"], [32, 3, 1, "", "named_parameters"], [32, 3, 1, "", "parameters"], [32, 3, 1, "", "register_backward_hook"], [32, 3, 1, "", "register_buffer"], [32, 3, 1, "", "register_forward_hook"], [32, 3, 1, "", "register_forward_pre_hook"], [32, 3, 1, "", "register_full_backward_hook"], [32, 3, 1, "", "register_full_backward_pre_hook"], [32, 3, 1, "", "register_load_state_dict_post_hook"], [32, 3, 1, "", "register_module"], [32, 3, 1, "", "register_parameter"], [32, 3, 1, "", "register_state_dict_pre_hook"], [32, 3, 1, "", "requires_grad_"], [32, 3, 1, "", "set_extra_state"], [32, 3, 1, "", "share_memory"], [32, 3, 1, "", "state_dict"], [32, 3, 1, "", "to"], [32, 3, 1, "", "to_empty"], [32, 3, 1, "", "train"], [32, 3, 1, "", "type"], [32, 3, 1, "", "xpu"], [32, 3, 1, "", "zero_grad"]], "mt_transformer.model.transformer_model.TransformerModel": [[33, 3, 1, "", "add_module"], [33, 3, 1, "", "apply"], [33, 3, 1, "", "bfloat16"], [33, 3, 1, "", "buffers"], [33, 3, 1, "", "children"], [33, 3, 1, "", "compile"], [33, 3, 1, "", "cpu"], [33, 3, 1, "", "cuda"], [33, 3, 1, "", "double"], [33, 3, 1, "", "eval"], [33, 3, 1, "", "extra_repr"], [33, 3, 1, "", "float"], [33, 3, 1, "", "forward"], [33, 3, 1, "", "get_buffer"], [33, 3, 1, "", "get_extra_state"], [33, 3, 1, "", "get_parameter"], [33, 3, 1, "", "get_submodule"], [33, 3, 1, "", "half"], [33, 3, 1, "", "ipu"], [33, 3, 1, "", "load_state_dict"], [33, 3, 1, "", "modules"], [33, 3, 1, "", "named_buffers"], [33, 3, 1, "", "named_children"], [33, 3, 1, "", "named_modules"], [33, 3, 1, "", "named_parameters"], [33, 3, 1, "", "parameters"], [33, 3, 1, "", "register_backward_hook"], [33, 3, 1, "", "register_buffer"], [33, 3, 1, "", "register_forward_hook"], [33, 3, 1, "", "register_forward_pre_hook"], [33, 3, 1, "", "register_full_backward_hook"], [33, 3, 1, "", "register_full_backward_pre_hook"], [33, 3, 1, "", "register_load_state_dict_post_hook"], [33, 3, 1, "", "register_module"], [33, 3, 1, "", "register_parameter"], [33, 3, 1, "", "register_state_dict_pre_hook"], [33, 3, 1, "", "requires_grad_"], [33, 3, 1, "", "set_extra_state"], [33, 3, 1, "", "share_memory"], [33, 3, 1, "", "state_dict"], [33, 3, 1, "", "to"], [33, 3, 1, "", "to_empty"], [33, 3, 1, "", "train"], [33, 3, 1, "", "type"], [33, 3, 1, "", "xpu"], [33, 3, 1, "", "zero_grad"]], "mt_transformer.trainer": [[37, 0, 0, "-", "transformer_trainer"], [39, 0, 0, "-", "transformer_validator"]], "mt_transformer.trainer.transformer_trainer": [[38, 1, 1, "", "TransformerTrainer"]], "mt_transformer.trainer.transformer_validator": [[40, 1, 1, "", "TransformerValidator"]]}, "objtypes": {"0": "py:module", "1": "py:class", "2": "py:function", "3": "py:method"}, "objnames": {"0": ["py", "module", "Python module"], "1": ["py", "class", "Python class"], "2": ["py", "function", "Python function"], "3": ["py", "method", "Python method"]}, "titleterms": {"mt_transform": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40], "config": [1, 2, 3], "project_config": [2, 3], "data_handl": [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], "data_load": [5, 6, 7], "create_tokenizers_dataload": 6, "get_raw_data_opus_book": 7, "data_token": [8, 9, 10, 11], "check_max_seq_length": 9, "get_all_text_sequences_form_dataset_in_languag": 10, "get_or_create_token": 11, "mask": [12, 13], "causal_mask": 13, "two_language_data_set": [14, 15], "twolanguagesdataset": 15, "model": [16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35], "greedy_decod": [17, 18], "greedydecod": 18, "layer": [19, 20, 21, 22, 23, 24, 25, 26], "feedforwardblock": 20, "layernorm": 21, "multiheadattent": 22, "positionalencod": 23, "projectionlay": 24, "residualconnect": 25, "tokenembed": 26, "transformer_model": [27, 28, 29, 30, 31, 32, 33, 34, 35], "decod": 28, "decoderstack": 29, "encod": 30, "encoderstackold": 31, "transform": [32, 42], "transformermodel": 33, "create_transform": 34, "get_transformer_model": 35, "trainer": [36, 37, 38, 39, 40], "transformer_train": [37, 38], "transformertrain": 38, "transformer_valid": [39, 40], "transformervalid": 40, "how": 42, "implement": 42, "architectur": 42, "from": 42, "scratch": 42}, "envversion": {"sphinx.domains.c": 3, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 9, "sphinx.domains.index": 1, "sphinx.domains.javascript": 3, "sphinx.domains.math": 2, "sphinx.domains.python": 4, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.intersphinx": 1, "sphinx.ext.viewcode": 1, "nbsphinx": 4, "sphinx": 60}, "alltitles": {"mt_transformer": [[0, "module-mt_transformer"]], "mt_transformer.config": [[1, "module-mt_transformer.config"]], "mt_transformer.config.project_config": [[2, "module-mt_transformer.config.project_config"]], "mt_transformer.config.project_config.Config": [[3, "mt-transformer-config-project-config-config"]], "mt_transformer.data_handler": [[4, "module-mt_transformer.data_handler"]], "mt_transformer.data_handler.data_loader": [[5, "module-mt_transformer.data_handler.data_loader"]], "mt_transformer.data_handler.data_loader.create_tokenizers_dataloaders": [[6, "mt-transformer-data-handler-data-loader-create-tokenizers-dataloaders"]], "mt_transformer.data_handler.data_loader.get_raw_data_opus_books": [[7, "mt-transformer-data-handler-data-loader-get-raw-data-opus-books"]], "mt_transformer.data_handler.data_tokenizer": [[8, "module-mt_transformer.data_handler.data_tokenizer"]], "mt_transformer.data_handler.data_tokenizer.check_max_seq_length": [[9, "mt-transformer-data-handler-data-tokenizer-check-max-seq-length"]], "mt_transformer.data_handler.data_tokenizer.get_all_text_sequences_form_dataset_in_language": [[10, "mt-transformer-data-handler-data-tokenizer-get-all-text-sequences-form-dataset-in-language"]], "mt_transformer.data_handler.data_tokenizer.get_or_create_tokenizer": [[11, "mt-transformer-data-handler-data-tokenizer-get-or-create-tokenizer"]], "mt_transformer.data_handler.masks": [[12, "module-mt_transformer.data_handler.masks"]], "mt_transformer.data_handler.masks.causal_mask": [[13, "mt-transformer-data-handler-masks-causal-mask"]], "mt_transformer.data_handler.two_language_data_set": [[14, "module-mt_transformer.data_handler.two_language_data_set"]], "mt_transformer.data_handler.two_language_data_set.TwoLanguagesDataset": [[15, "mt-transformer-data-handler-two-language-data-set-twolanguagesdataset"]], "mt_transformer.model": [[16, "module-mt_transformer.model"]], "mt_transformer.model.greedy_decoder": [[17, "module-mt_transformer.model.greedy_decoder"]], "mt_transformer.model.greedy_decoder.GreedyDecoder": [[18, "mt-transformer-model-greedy-decoder-greedydecoder"]], "mt_transformer.model.layers": [[19, "module-mt_transformer.model.layers"]], "mt_transformer.model.layers.FeedForwardBlock": [[20, "mt-transformer-model-layers-feedforwardblock"]], "mt_transformer.model.layers.LayerNormalization": [[21, "mt-transformer-model-layers-layernormalization"]], "mt_transformer.model.layers.MultiHeadAttention": [[22, "mt-transformer-model-layers-multiheadattention"]], "mt_transformer.model.layers.PositionalEncoding": [[23, "mt-transformer-model-layers-positionalencoding"]], "mt_transformer.model.layers.ProjectionLayer": [[24, "mt-transformer-model-layers-projectionlayer"]], "mt_transformer.model.layers.ResidualConnection": [[25, "mt-transformer-model-layers-residualconnection"]], "mt_transformer.model.layers.TokenEmbeddings": [[26, "mt-transformer-model-layers-tokenembeddings"]], "mt_transformer.model.transformer_model": [[27, "module-mt_transformer.model.transformer_model"]], "mt_transformer.model.transformer_model.Decoder": [[28, "mt-transformer-model-transformer-model-decoder"]], "mt_transformer.model.transformer_model.DecoderStack": [[29, "mt-transformer-model-transformer-model-decoderstack"]], "mt_transformer.model.transformer_model.Encoder": [[30, "mt-transformer-model-transformer-model-encoder"]], "mt_transformer.model.transformer_model.EncoderStackOld": [[31, "mt-transformer-model-transformer-model-encoderstackold"]], "mt_transformer.model.transformer_model.Transformer": [[32, "mt-transformer-model-transformer-model-transformer"]], "mt_transformer.model.transformer_model.TransformerModel": [[33, "mt-transformer-model-transformer-model-transformermodel"]], "mt_transformer.model.transformer_model.create_transformer": [[34, "mt-transformer-model-transformer-model-create-transformer"]], "mt_transformer.model.transformer_model.get_transformer_model": [[35, "mt-transformer-model-transformer-model-get-transformer-model"]], "mt_transformer.trainer": [[36, "module-mt_transformer.trainer"]], "mt_transformer.trainer.transformer_trainer": [[37, "module-mt_transformer.trainer.transformer_trainer"]], "mt_transformer.trainer.transformer_trainer.TransformerTrainer": [[38, "mt-transformer-trainer-transformer-trainer-transformertrainer"]], "mt_transformer.trainer.transformer_validator": [[39, "module-mt_transformer.trainer.transformer_validator"]], "mt_transformer.trainer.transformer_validator.TransformerValidator": [[40, "mt-transformer-trainer-transformer-validator-transformervalidator"]], "How to implement a transformer architecture from scratch ?": [[42, "how-to-implement-a-transformer-architecture-from-scratch"]]}, "indexentries": {"module": [[0, "module-mt_transformer"], [1, "module-mt_transformer.config"], [2, "module-mt_transformer.config.project_config"], [4, "module-mt_transformer.data_handler"], [5, "module-mt_transformer.data_handler.data_loader"], [8, "module-mt_transformer.data_handler.data_tokenizer"], [12, "module-mt_transformer.data_handler.masks"], [14, "module-mt_transformer.data_handler.two_language_data_set"], [16, "module-mt_transformer.model"], [17, "module-mt_transformer.model.greedy_decoder"], [19, "module-mt_transformer.model.layers"], [27, "module-mt_transformer.model.transformer_model"], [36, "module-mt_transformer.trainer"], [37, "module-mt_transformer.trainer.transformer_trainer"], [39, "module-mt_transformer.trainer.transformer_validator"]], "mt_transformer": [[0, "module-mt_transformer"]], "mt_transformer.config": [[1, "module-mt_transformer.config"]], "mt_transformer.config.project_config": [[2, "module-mt_transformer.config.project_config"]], "config (class in mt_transformer.config.project_config)": [[3, "mt_transformer.config.project_config.Config"]], "mt_transformer.data_handler": [[4, "module-mt_transformer.data_handler"]], "mt_transformer.data_handler.data_loader": [[5, "module-mt_transformer.data_handler.data_loader"]], "create_tokenizers_dataloaders() (in module mt_transformer.data_handler.data_loader)": [[6, "mt_transformer.data_handler.data_loader.create_tokenizers_dataloaders"]], "get_raw_data_opus_books() (in module mt_transformer.data_handler.data_loader)": [[7, "mt_transformer.data_handler.data_loader.get_raw_data_opus_books"]], "mt_transformer.data_handler.data_tokenizer": [[8, "module-mt_transformer.data_handler.data_tokenizer"]], "check_max_seq_length() (in module mt_transformer.data_handler.data_tokenizer)": [[9, "mt_transformer.data_handler.data_tokenizer.check_max_seq_length"]], "get_all_text_sequences_form_dataset_in_language() (in module mt_transformer.data_handler.data_tokenizer)": [[10, "mt_transformer.data_handler.data_tokenizer.get_all_text_sequences_form_dataset_in_language"]], "get_or_create_tokenizer() (in module mt_transformer.data_handler.data_tokenizer)": [[11, "mt_transformer.data_handler.data_tokenizer.get_or_create_tokenizer"]], "mt_transformer.data_handler.masks": [[12, "module-mt_transformer.data_handler.masks"]], "causal_mask() (in module mt_transformer.data_handler.masks)": [[13, "mt_transformer.data_handler.masks.causal_mask"]], "mt_transformer.data_handler.two_language_data_set": [[14, "module-mt_transformer.data_handler.two_language_data_set"]], "twolanguagesdataset (class in mt_transformer.data_handler.two_language_data_set)": [[15, "mt_transformer.data_handler.two_language_data_set.TwoLanguagesDataset"]], "mt_transformer.model": [[16, "module-mt_transformer.model"]], "mt_transformer.model.greedy_decoder": [[17, "module-mt_transformer.model.greedy_decoder"]], "greedydecoder (class in mt_transformer.model.greedy_decoder)": [[18, "mt_transformer.model.greedy_decoder.GreedyDecoder"]], "mt_transformer.model.layers": [[19, "module-mt_transformer.model.layers"]], "feedforwardblock (class in mt_transformer.model.layers)": [[20, "mt_transformer.model.layers.FeedForwardBlock"]], "add_module() (feedforwardblock method)": [[20, "mt_transformer.model.layers.FeedForwardBlock.add_module"]], "apply() (feedforwardblock method)": [[20, "mt_transformer.model.layers.FeedForwardBlock.apply"]], "bfloat16() (feedforwardblock method)": [[20, "mt_transformer.model.layers.FeedForwardBlock.bfloat16"]], "buffers() (feedforwardblock method)": [[20, "mt_transformer.model.layers.FeedForwardBlock.buffers"]], "children() (feedforwardblock method)": [[20, "mt_transformer.model.layers.FeedForwardBlock.children"]], "compile() (feedforwardblock method)": [[20, "mt_transformer.model.layers.FeedForwardBlock.compile"]], "cpu() (feedforwardblock method)": [[20, "mt_transformer.model.layers.FeedForwardBlock.cpu"]], "cuda() (feedforwardblock method)": [[20, "mt_transformer.model.layers.FeedForwardBlock.cuda"]], "double() (feedforwardblock method)": [[20, "mt_transformer.model.layers.FeedForwardBlock.double"]], "eval() (feedforwardblock method)": [[20, "mt_transformer.model.layers.FeedForwardBlock.eval"]], "extra_repr() (feedforwardblock method)": [[20, "mt_transformer.model.layers.FeedForwardBlock.extra_repr"]], "float() (feedforwardblock method)": [[20, "mt_transformer.model.layers.FeedForwardBlock.float"]], "get_buffer() (feedforwardblock method)": [[20, "mt_transformer.model.layers.FeedForwardBlock.get_buffer"]], "get_extra_state() (feedforwardblock method)": [[20, "mt_transformer.model.layers.FeedForwardBlock.get_extra_state"]], "get_parameter() (feedforwardblock method)": [[20, "mt_transformer.model.layers.FeedForwardBlock.get_parameter"]], "get_submodule() (feedforwardblock method)": [[20, "mt_transformer.model.layers.FeedForwardBlock.get_submodule"]], "half() (feedforwardblock method)": [[20, "mt_transformer.model.layers.FeedForwardBlock.half"]], "ipu() (feedforwardblock method)": [[20, "mt_transformer.model.layers.FeedForwardBlock.ipu"]], "load_state_dict() (feedforwardblock method)": [[20, "mt_transformer.model.layers.FeedForwardBlock.load_state_dict"]], "modules() (feedforwardblock method)": [[20, "mt_transformer.model.layers.FeedForwardBlock.modules"]], "named_buffers() (feedforwardblock method)": [[20, "mt_transformer.model.layers.FeedForwardBlock.named_buffers"]], "named_children() (feedforwardblock method)": [[20, "mt_transformer.model.layers.FeedForwardBlock.named_children"]], "named_modules() (feedforwardblock method)": [[20, "mt_transformer.model.layers.FeedForwardBlock.named_modules"]], "named_parameters() (feedforwardblock method)": [[20, "mt_transformer.model.layers.FeedForwardBlock.named_parameters"]], "parameters() (feedforwardblock method)": [[20, "mt_transformer.model.layers.FeedForwardBlock.parameters"]], "register_backward_hook() (feedforwardblock method)": [[20, "mt_transformer.model.layers.FeedForwardBlock.register_backward_hook"]], "register_buffer() (feedforwardblock method)": [[20, "mt_transformer.model.layers.FeedForwardBlock.register_buffer"]], "register_forward_hook() (feedforwardblock method)": [[20, "mt_transformer.model.layers.FeedForwardBlock.register_forward_hook"]], "register_forward_pre_hook() (feedforwardblock method)": [[20, "mt_transformer.model.layers.FeedForwardBlock.register_forward_pre_hook"]], "register_full_backward_hook() (feedforwardblock method)": [[20, "mt_transformer.model.layers.FeedForwardBlock.register_full_backward_hook"]], "register_full_backward_pre_hook() (feedforwardblock method)": [[20, "mt_transformer.model.layers.FeedForwardBlock.register_full_backward_pre_hook"]], "register_load_state_dict_post_hook() (feedforwardblock method)": [[20, "mt_transformer.model.layers.FeedForwardBlock.register_load_state_dict_post_hook"]], "register_module() (feedforwardblock method)": [[20, "mt_transformer.model.layers.FeedForwardBlock.register_module"]], "register_parameter() (feedforwardblock method)": [[20, "mt_transformer.model.layers.FeedForwardBlock.register_parameter"]], "register_state_dict_pre_hook() (feedforwardblock method)": [[20, "mt_transformer.model.layers.FeedForwardBlock.register_state_dict_pre_hook"]], "requires_grad_() (feedforwardblock method)": [[20, "mt_transformer.model.layers.FeedForwardBlock.requires_grad_"]], "set_extra_state() (feedforwardblock method)": [[20, "mt_transformer.model.layers.FeedForwardBlock.set_extra_state"]], "share_memory() (feedforwardblock method)": [[20, "mt_transformer.model.layers.FeedForwardBlock.share_memory"]], "state_dict() (feedforwardblock method)": [[20, "mt_transformer.model.layers.FeedForwardBlock.state_dict"]], "to() (feedforwardblock method)": [[20, "mt_transformer.model.layers.FeedForwardBlock.to"]], "to_empty() (feedforwardblock method)": [[20, "mt_transformer.model.layers.FeedForwardBlock.to_empty"]], "train() (feedforwardblock method)": [[20, "mt_transformer.model.layers.FeedForwardBlock.train"]], "type() (feedforwardblock method)": [[20, "mt_transformer.model.layers.FeedForwardBlock.type"]], "xpu() (feedforwardblock method)": [[20, "mt_transformer.model.layers.FeedForwardBlock.xpu"]], "zero_grad() (feedforwardblock method)": [[20, "mt_transformer.model.layers.FeedForwardBlock.zero_grad"]], "layernormalization (class in mt_transformer.model.layers)": [[21, "mt_transformer.model.layers.LayerNormalization"]], "add_module() (layernormalization method)": [[21, "mt_transformer.model.layers.LayerNormalization.add_module"]], "apply() (layernormalization method)": [[21, "mt_transformer.model.layers.LayerNormalization.apply"]], "bfloat16() (layernormalization method)": [[21, "mt_transformer.model.layers.LayerNormalization.bfloat16"]], "buffers() (layernormalization method)": [[21, "mt_transformer.model.layers.LayerNormalization.buffers"]], "children() (layernormalization method)": [[21, "mt_transformer.model.layers.LayerNormalization.children"]], "compile() (layernormalization method)": [[21, "mt_transformer.model.layers.LayerNormalization.compile"]], "cpu() (layernormalization method)": [[21, "mt_transformer.model.layers.LayerNormalization.cpu"]], "cuda() (layernormalization method)": [[21, "mt_transformer.model.layers.LayerNormalization.cuda"]], "double() (layernormalization method)": [[21, "mt_transformer.model.layers.LayerNormalization.double"]], "eval() (layernormalization method)": [[21, "mt_transformer.model.layers.LayerNormalization.eval"]], "extra_repr() (layernormalization method)": [[21, "mt_transformer.model.layers.LayerNormalization.extra_repr"]], "float() (layernormalization method)": [[21, "mt_transformer.model.layers.LayerNormalization.float"]], "get_buffer() (layernormalization method)": [[21, "mt_transformer.model.layers.LayerNormalization.get_buffer"]], "get_extra_state() (layernormalization method)": [[21, "mt_transformer.model.layers.LayerNormalization.get_extra_state"]], "get_parameter() (layernormalization method)": [[21, "mt_transformer.model.layers.LayerNormalization.get_parameter"]], "get_submodule() (layernormalization method)": [[21, "mt_transformer.model.layers.LayerNormalization.get_submodule"]], "half() (layernormalization method)": [[21, "mt_transformer.model.layers.LayerNormalization.half"]], "ipu() (layernormalization method)": [[21, "mt_transformer.model.layers.LayerNormalization.ipu"]], "load_state_dict() (layernormalization method)": [[21, "mt_transformer.model.layers.LayerNormalization.load_state_dict"]], "modules() (layernormalization method)": [[21, "mt_transformer.model.layers.LayerNormalization.modules"]], "named_buffers() (layernormalization method)": [[21, "mt_transformer.model.layers.LayerNormalization.named_buffers"]], "named_children() (layernormalization method)": [[21, "mt_transformer.model.layers.LayerNormalization.named_children"]], "named_modules() (layernormalization method)": [[21, "mt_transformer.model.layers.LayerNormalization.named_modules"]], "named_parameters() (layernormalization method)": [[21, "mt_transformer.model.layers.LayerNormalization.named_parameters"]], "parameters() (layernormalization method)": [[21, "mt_transformer.model.layers.LayerNormalization.parameters"]], "register_backward_hook() (layernormalization method)": [[21, "mt_transformer.model.layers.LayerNormalization.register_backward_hook"]], "register_buffer() (layernormalization method)": [[21, "mt_transformer.model.layers.LayerNormalization.register_buffer"]], "register_forward_hook() (layernormalization method)": [[21, "mt_transformer.model.layers.LayerNormalization.register_forward_hook"]], "register_forward_pre_hook() (layernormalization method)": [[21, "mt_transformer.model.layers.LayerNormalization.register_forward_pre_hook"]], "register_full_backward_hook() (layernormalization method)": [[21, "mt_transformer.model.layers.LayerNormalization.register_full_backward_hook"]], "register_full_backward_pre_hook() (layernormalization method)": [[21, "mt_transformer.model.layers.LayerNormalization.register_full_backward_pre_hook"]], "register_load_state_dict_post_hook() (layernormalization method)": [[21, "mt_transformer.model.layers.LayerNormalization.register_load_state_dict_post_hook"]], "register_module() (layernormalization method)": [[21, "mt_transformer.model.layers.LayerNormalization.register_module"]], "register_parameter() (layernormalization method)": [[21, "mt_transformer.model.layers.LayerNormalization.register_parameter"]], "register_state_dict_pre_hook() (layernormalization method)": [[21, "mt_transformer.model.layers.LayerNormalization.register_state_dict_pre_hook"]], "requires_grad_() (layernormalization method)": [[21, "mt_transformer.model.layers.LayerNormalization.requires_grad_"]], "set_extra_state() (layernormalization method)": [[21, "mt_transformer.model.layers.LayerNormalization.set_extra_state"]], "share_memory() (layernormalization method)": [[21, "mt_transformer.model.layers.LayerNormalization.share_memory"]], "state_dict() (layernormalization method)": [[21, "mt_transformer.model.layers.LayerNormalization.state_dict"]], "to() (layernormalization method)": [[21, "mt_transformer.model.layers.LayerNormalization.to"]], "to_empty() (layernormalization method)": [[21, "mt_transformer.model.layers.LayerNormalization.to_empty"]], "train() (layernormalization method)": [[21, "mt_transformer.model.layers.LayerNormalization.train"]], "type() (layernormalization method)": [[21, "mt_transformer.model.layers.LayerNormalization.type"]], "xpu() (layernormalization method)": [[21, "mt_transformer.model.layers.LayerNormalization.xpu"]], "zero_grad() (layernormalization method)": [[21, "mt_transformer.model.layers.LayerNormalization.zero_grad"]], "multiheadattention (class in mt_transformer.model.layers)": [[22, "mt_transformer.model.layers.MultiHeadAttention"]], "add_module() (multiheadattention method)": [[22, "mt_transformer.model.layers.MultiHeadAttention.add_module"]], "apply() (multiheadattention method)": [[22, "mt_transformer.model.layers.MultiHeadAttention.apply"]], "bfloat16() (multiheadattention method)": [[22, "mt_transformer.model.layers.MultiHeadAttention.bfloat16"]], "buffers() (multiheadattention method)": [[22, "mt_transformer.model.layers.MultiHeadAttention.buffers"]], "children() (multiheadattention method)": [[22, "mt_transformer.model.layers.MultiHeadAttention.children"]], "compile() (multiheadattention method)": [[22, "mt_transformer.model.layers.MultiHeadAttention.compile"]], "cpu() (multiheadattention method)": [[22, "mt_transformer.model.layers.MultiHeadAttention.cpu"]], "cuda() (multiheadattention method)": [[22, "mt_transformer.model.layers.MultiHeadAttention.cuda"]], "double() (multiheadattention method)": [[22, "mt_transformer.model.layers.MultiHeadAttention.double"]], "eval() (multiheadattention method)": [[22, "mt_transformer.model.layers.MultiHeadAttention.eval"]], "extra_repr() (multiheadattention method)": [[22, "mt_transformer.model.layers.MultiHeadAttention.extra_repr"]], "float() (multiheadattention method)": [[22, "mt_transformer.model.layers.MultiHeadAttention.float"]], "get_buffer() (multiheadattention method)": [[22, "mt_transformer.model.layers.MultiHeadAttention.get_buffer"]], "get_extra_state() (multiheadattention method)": [[22, "mt_transformer.model.layers.MultiHeadAttention.get_extra_state"]], "get_parameter() (multiheadattention method)": [[22, "mt_transformer.model.layers.MultiHeadAttention.get_parameter"]], "get_submodule() (multiheadattention method)": [[22, "mt_transformer.model.layers.MultiHeadAttention.get_submodule"]], "half() (multiheadattention method)": [[22, "mt_transformer.model.layers.MultiHeadAttention.half"]], "ipu() (multiheadattention method)": [[22, "mt_transformer.model.layers.MultiHeadAttention.ipu"]], "load_state_dict() (multiheadattention method)": [[22, "mt_transformer.model.layers.MultiHeadAttention.load_state_dict"]], "modules() (multiheadattention method)": [[22, "mt_transformer.model.layers.MultiHeadAttention.modules"]], "named_buffers() (multiheadattention method)": [[22, "mt_transformer.model.layers.MultiHeadAttention.named_buffers"]], "named_children() (multiheadattention method)": [[22, "mt_transformer.model.layers.MultiHeadAttention.named_children"]], "named_modules() (multiheadattention method)": [[22, "mt_transformer.model.layers.MultiHeadAttention.named_modules"]], "named_parameters() (multiheadattention method)": [[22, "mt_transformer.model.layers.MultiHeadAttention.named_parameters"]], "parameters() (multiheadattention method)": [[22, "mt_transformer.model.layers.MultiHeadAttention.parameters"]], "register_backward_hook() (multiheadattention method)": [[22, "mt_transformer.model.layers.MultiHeadAttention.register_backward_hook"]], "register_buffer() (multiheadattention method)": [[22, "mt_transformer.model.layers.MultiHeadAttention.register_buffer"]], "register_forward_hook() (multiheadattention method)": [[22, "mt_transformer.model.layers.MultiHeadAttention.register_forward_hook"]], "register_forward_pre_hook() (multiheadattention method)": [[22, "mt_transformer.model.layers.MultiHeadAttention.register_forward_pre_hook"]], "register_full_backward_hook() (multiheadattention method)": [[22, "mt_transformer.model.layers.MultiHeadAttention.register_full_backward_hook"]], "register_full_backward_pre_hook() (multiheadattention method)": [[22, "mt_transformer.model.layers.MultiHeadAttention.register_full_backward_pre_hook"]], "register_load_state_dict_post_hook() (multiheadattention method)": [[22, "mt_transformer.model.layers.MultiHeadAttention.register_load_state_dict_post_hook"]], "register_module() (multiheadattention method)": [[22, "mt_transformer.model.layers.MultiHeadAttention.register_module"]], "register_parameter() (multiheadattention method)": [[22, "mt_transformer.model.layers.MultiHeadAttention.register_parameter"]], "register_state_dict_pre_hook() (multiheadattention method)": [[22, "mt_transformer.model.layers.MultiHeadAttention.register_state_dict_pre_hook"]], "requires_grad_() (multiheadattention method)": [[22, "mt_transformer.model.layers.MultiHeadAttention.requires_grad_"]], "set_extra_state() (multiheadattention method)": [[22, "mt_transformer.model.layers.MultiHeadAttention.set_extra_state"]], "share_memory() (multiheadattention method)": [[22, "mt_transformer.model.layers.MultiHeadAttention.share_memory"]], "state_dict() (multiheadattention method)": [[22, "mt_transformer.model.layers.MultiHeadAttention.state_dict"]], "to() (multiheadattention method)": [[22, "mt_transformer.model.layers.MultiHeadAttention.to"]], "to_empty() (multiheadattention method)": [[22, "mt_transformer.model.layers.MultiHeadAttention.to_empty"]], "train() (multiheadattention method)": [[22, "mt_transformer.model.layers.MultiHeadAttention.train"]], "type() (multiheadattention method)": [[22, "mt_transformer.model.layers.MultiHeadAttention.type"]], "xpu() (multiheadattention method)": [[22, "mt_transformer.model.layers.MultiHeadAttention.xpu"]], "zero_grad() (multiheadattention method)": [[22, "mt_transformer.model.layers.MultiHeadAttention.zero_grad"]], "positionalencoding (class in mt_transformer.model.layers)": [[23, "mt_transformer.model.layers.PositionalEncoding"]], "add_module() (positionalencoding method)": [[23, "mt_transformer.model.layers.PositionalEncoding.add_module"]], "apply() (positionalencoding method)": [[23, "mt_transformer.model.layers.PositionalEncoding.apply"]], "bfloat16() (positionalencoding method)": [[23, "mt_transformer.model.layers.PositionalEncoding.bfloat16"]], "buffers() (positionalencoding method)": [[23, "mt_transformer.model.layers.PositionalEncoding.buffers"]], "children() (positionalencoding method)": [[23, "mt_transformer.model.layers.PositionalEncoding.children"]], "compile() (positionalencoding method)": [[23, "mt_transformer.model.layers.PositionalEncoding.compile"]], "cpu() (positionalencoding method)": [[23, "mt_transformer.model.layers.PositionalEncoding.cpu"]], "cuda() (positionalencoding method)": [[23, "mt_transformer.model.layers.PositionalEncoding.cuda"]], "double() (positionalencoding method)": [[23, "mt_transformer.model.layers.PositionalEncoding.double"]], "eval() (positionalencoding method)": [[23, "mt_transformer.model.layers.PositionalEncoding.eval"]], "extra_repr() (positionalencoding method)": [[23, "mt_transformer.model.layers.PositionalEncoding.extra_repr"]], "float() (positionalencoding method)": [[23, "mt_transformer.model.layers.PositionalEncoding.float"]], "forward() (positionalencoding method)": [[23, "mt_transformer.model.layers.PositionalEncoding.forward"]], "get_buffer() (positionalencoding method)": [[23, "mt_transformer.model.layers.PositionalEncoding.get_buffer"]], "get_extra_state() (positionalencoding method)": [[23, "mt_transformer.model.layers.PositionalEncoding.get_extra_state"]], "get_parameter() (positionalencoding method)": [[23, "mt_transformer.model.layers.PositionalEncoding.get_parameter"]], "get_submodule() (positionalencoding method)": [[23, "mt_transformer.model.layers.PositionalEncoding.get_submodule"]], "half() (positionalencoding method)": [[23, "mt_transformer.model.layers.PositionalEncoding.half"]], "ipu() (positionalencoding method)": [[23, "mt_transformer.model.layers.PositionalEncoding.ipu"]], "load_state_dict() (positionalencoding method)": [[23, "mt_transformer.model.layers.PositionalEncoding.load_state_dict"]], "modules() (positionalencoding method)": [[23, "mt_transformer.model.layers.PositionalEncoding.modules"]], "named_buffers() (positionalencoding method)": [[23, "mt_transformer.model.layers.PositionalEncoding.named_buffers"]], "named_children() (positionalencoding method)": [[23, "mt_transformer.model.layers.PositionalEncoding.named_children"]], "named_modules() (positionalencoding method)": [[23, "mt_transformer.model.layers.PositionalEncoding.named_modules"]], "named_parameters() (positionalencoding method)": [[23, "mt_transformer.model.layers.PositionalEncoding.named_parameters"]], "parameters() (positionalencoding method)": [[23, "mt_transformer.model.layers.PositionalEncoding.parameters"]], "register_backward_hook() (positionalencoding method)": [[23, "mt_transformer.model.layers.PositionalEncoding.register_backward_hook"]], "register_buffer() (positionalencoding method)": [[23, "mt_transformer.model.layers.PositionalEncoding.register_buffer"]], "register_forward_hook() (positionalencoding method)": [[23, "mt_transformer.model.layers.PositionalEncoding.register_forward_hook"]], "register_forward_pre_hook() (positionalencoding method)": [[23, "mt_transformer.model.layers.PositionalEncoding.register_forward_pre_hook"]], "register_full_backward_hook() (positionalencoding method)": [[23, "mt_transformer.model.layers.PositionalEncoding.register_full_backward_hook"]], "register_full_backward_pre_hook() (positionalencoding method)": [[23, "mt_transformer.model.layers.PositionalEncoding.register_full_backward_pre_hook"]], "register_load_state_dict_post_hook() (positionalencoding method)": [[23, "mt_transformer.model.layers.PositionalEncoding.register_load_state_dict_post_hook"]], "register_module() (positionalencoding method)": [[23, "mt_transformer.model.layers.PositionalEncoding.register_module"]], "register_parameter() (positionalencoding method)": [[23, "mt_transformer.model.layers.PositionalEncoding.register_parameter"]], "register_state_dict_pre_hook() (positionalencoding method)": [[23, "mt_transformer.model.layers.PositionalEncoding.register_state_dict_pre_hook"]], "requires_grad_() (positionalencoding method)": [[23, "mt_transformer.model.layers.PositionalEncoding.requires_grad_"]], "set_extra_state() (positionalencoding method)": [[23, "mt_transformer.model.layers.PositionalEncoding.set_extra_state"]], "share_memory() (positionalencoding method)": [[23, "mt_transformer.model.layers.PositionalEncoding.share_memory"]], "state_dict() (positionalencoding method)": [[23, "mt_transformer.model.layers.PositionalEncoding.state_dict"]], "to() (positionalencoding method)": [[23, "mt_transformer.model.layers.PositionalEncoding.to"]], "to_empty() (positionalencoding method)": [[23, "mt_transformer.model.layers.PositionalEncoding.to_empty"]], "train() (positionalencoding method)": [[23, "mt_transformer.model.layers.PositionalEncoding.train"]], "type() (positionalencoding method)": [[23, "mt_transformer.model.layers.PositionalEncoding.type"]], "xpu() (positionalencoding method)": [[23, "mt_transformer.model.layers.PositionalEncoding.xpu"]], "zero_grad() (positionalencoding method)": [[23, "mt_transformer.model.layers.PositionalEncoding.zero_grad"]], "projectionlayer (class in mt_transformer.model.layers)": [[24, "mt_transformer.model.layers.ProjectionLayer"]], "add_module() (projectionlayer method)": [[24, "mt_transformer.model.layers.ProjectionLayer.add_module"]], "apply() (projectionlayer method)": [[24, "mt_transformer.model.layers.ProjectionLayer.apply"]], "bfloat16() (projectionlayer method)": [[24, "mt_transformer.model.layers.ProjectionLayer.bfloat16"]], "buffers() (projectionlayer method)": [[24, "mt_transformer.model.layers.ProjectionLayer.buffers"]], "children() (projectionlayer method)": [[24, "mt_transformer.model.layers.ProjectionLayer.children"]], "compile() (projectionlayer method)": [[24, "mt_transformer.model.layers.ProjectionLayer.compile"]], "cpu() (projectionlayer method)": [[24, "mt_transformer.model.layers.ProjectionLayer.cpu"]], "cuda() (projectionlayer method)": [[24, "mt_transformer.model.layers.ProjectionLayer.cuda"]], "double() (projectionlayer method)": [[24, "mt_transformer.model.layers.ProjectionLayer.double"]], "eval() (projectionlayer method)": [[24, "mt_transformer.model.layers.ProjectionLayer.eval"]], "extra_repr() (projectionlayer method)": [[24, "mt_transformer.model.layers.ProjectionLayer.extra_repr"]], "float() (projectionlayer method)": [[24, "mt_transformer.model.layers.ProjectionLayer.float"]], "get_buffer() (projectionlayer method)": [[24, "mt_transformer.model.layers.ProjectionLayer.get_buffer"]], "get_extra_state() (projectionlayer method)": [[24, "mt_transformer.model.layers.ProjectionLayer.get_extra_state"]], "get_parameter() (projectionlayer method)": [[24, "mt_transformer.model.layers.ProjectionLayer.get_parameter"]], "get_submodule() (projectionlayer method)": [[24, "mt_transformer.model.layers.ProjectionLayer.get_submodule"]], "half() (projectionlayer method)": [[24, "mt_transformer.model.layers.ProjectionLayer.half"]], "ipu() (projectionlayer method)": [[24, "mt_transformer.model.layers.ProjectionLayer.ipu"]], "load_state_dict() (projectionlayer method)": [[24, "mt_transformer.model.layers.ProjectionLayer.load_state_dict"]], "modules() (projectionlayer method)": [[24, "mt_transformer.model.layers.ProjectionLayer.modules"]], "named_buffers() (projectionlayer method)": [[24, "mt_transformer.model.layers.ProjectionLayer.named_buffers"]], "named_children() (projectionlayer method)": [[24, "mt_transformer.model.layers.ProjectionLayer.named_children"]], "named_modules() (projectionlayer method)": [[24, "mt_transformer.model.layers.ProjectionLayer.named_modules"]], "named_parameters() (projectionlayer method)": [[24, "mt_transformer.model.layers.ProjectionLayer.named_parameters"]], "parameters() (projectionlayer method)": [[24, "mt_transformer.model.layers.ProjectionLayer.parameters"]], "register_backward_hook() (projectionlayer method)": [[24, "mt_transformer.model.layers.ProjectionLayer.register_backward_hook"]], "register_buffer() (projectionlayer method)": [[24, "mt_transformer.model.layers.ProjectionLayer.register_buffer"]], "register_forward_hook() (projectionlayer method)": [[24, "mt_transformer.model.layers.ProjectionLayer.register_forward_hook"]], "register_forward_pre_hook() (projectionlayer method)": [[24, "mt_transformer.model.layers.ProjectionLayer.register_forward_pre_hook"]], "register_full_backward_hook() (projectionlayer method)": [[24, "mt_transformer.model.layers.ProjectionLayer.register_full_backward_hook"]], "register_full_backward_pre_hook() (projectionlayer method)": [[24, "mt_transformer.model.layers.ProjectionLayer.register_full_backward_pre_hook"]], "register_load_state_dict_post_hook() (projectionlayer method)": [[24, "mt_transformer.model.layers.ProjectionLayer.register_load_state_dict_post_hook"]], "register_module() (projectionlayer method)": [[24, "mt_transformer.model.layers.ProjectionLayer.register_module"]], "register_parameter() (projectionlayer method)": [[24, "mt_transformer.model.layers.ProjectionLayer.register_parameter"]], "register_state_dict_pre_hook() (projectionlayer method)": [[24, "mt_transformer.model.layers.ProjectionLayer.register_state_dict_pre_hook"]], "requires_grad_() (projectionlayer method)": [[24, "mt_transformer.model.layers.ProjectionLayer.requires_grad_"]], "set_extra_state() (projectionlayer method)": [[24, "mt_transformer.model.layers.ProjectionLayer.set_extra_state"]], "share_memory() (projectionlayer method)": [[24, "mt_transformer.model.layers.ProjectionLayer.share_memory"]], "state_dict() (projectionlayer method)": [[24, "mt_transformer.model.layers.ProjectionLayer.state_dict"]], "to() (projectionlayer method)": [[24, "mt_transformer.model.layers.ProjectionLayer.to"]], "to_empty() (projectionlayer method)": [[24, "mt_transformer.model.layers.ProjectionLayer.to_empty"]], "train() (projectionlayer method)": [[24, "mt_transformer.model.layers.ProjectionLayer.train"]], "type() (projectionlayer method)": [[24, "mt_transformer.model.layers.ProjectionLayer.type"]], "xpu() (projectionlayer method)": [[24, "mt_transformer.model.layers.ProjectionLayer.xpu"]], "zero_grad() (projectionlayer method)": [[24, "mt_transformer.model.layers.ProjectionLayer.zero_grad"]], "residualconnection (class in mt_transformer.model.layers)": [[25, "mt_transformer.model.layers.ResidualConnection"]], "add_module() (residualconnection method)": [[25, "mt_transformer.model.layers.ResidualConnection.add_module"]], "apply() (residualconnection method)": [[25, "mt_transformer.model.layers.ResidualConnection.apply"]], "bfloat16() (residualconnection method)": [[25, "mt_transformer.model.layers.ResidualConnection.bfloat16"]], "buffers() (residualconnection method)": [[25, "mt_transformer.model.layers.ResidualConnection.buffers"]], "children() (residualconnection method)": [[25, "mt_transformer.model.layers.ResidualConnection.children"]], "compile() (residualconnection method)": [[25, "mt_transformer.model.layers.ResidualConnection.compile"]], "cpu() (residualconnection method)": [[25, "mt_transformer.model.layers.ResidualConnection.cpu"]], "cuda() (residualconnection method)": [[25, "mt_transformer.model.layers.ResidualConnection.cuda"]], "double() (residualconnection method)": [[25, "mt_transformer.model.layers.ResidualConnection.double"]], "eval() (residualconnection method)": [[25, "mt_transformer.model.layers.ResidualConnection.eval"]], "extra_repr() (residualconnection method)": [[25, "mt_transformer.model.layers.ResidualConnection.extra_repr"]], "float() (residualconnection method)": [[25, "mt_transformer.model.layers.ResidualConnection.float"]], "get_buffer() (residualconnection method)": [[25, "mt_transformer.model.layers.ResidualConnection.get_buffer"]], "get_extra_state() (residualconnection method)": [[25, "mt_transformer.model.layers.ResidualConnection.get_extra_state"]], "get_parameter() (residualconnection method)": [[25, "mt_transformer.model.layers.ResidualConnection.get_parameter"]], "get_submodule() (residualconnection method)": [[25, "mt_transformer.model.layers.ResidualConnection.get_submodule"]], "half() (residualconnection method)": [[25, "mt_transformer.model.layers.ResidualConnection.half"]], "ipu() (residualconnection method)": [[25, "mt_transformer.model.layers.ResidualConnection.ipu"]], "load_state_dict() (residualconnection method)": [[25, "mt_transformer.model.layers.ResidualConnection.load_state_dict"]], "modules() (residualconnection method)": [[25, "mt_transformer.model.layers.ResidualConnection.modules"]], "named_buffers() (residualconnection method)": [[25, "mt_transformer.model.layers.ResidualConnection.named_buffers"]], "named_children() (residualconnection method)": [[25, "mt_transformer.model.layers.ResidualConnection.named_children"]], "named_modules() (residualconnection method)": [[25, "mt_transformer.model.layers.ResidualConnection.named_modules"]], "named_parameters() (residualconnection method)": [[25, "mt_transformer.model.layers.ResidualConnection.named_parameters"]], "parameters() (residualconnection method)": [[25, "mt_transformer.model.layers.ResidualConnection.parameters"]], "register_backward_hook() (residualconnection method)": [[25, "mt_transformer.model.layers.ResidualConnection.register_backward_hook"]], "register_buffer() (residualconnection method)": [[25, "mt_transformer.model.layers.ResidualConnection.register_buffer"]], "register_forward_hook() (residualconnection method)": [[25, "mt_transformer.model.layers.ResidualConnection.register_forward_hook"]], "register_forward_pre_hook() (residualconnection method)": [[25, "mt_transformer.model.layers.ResidualConnection.register_forward_pre_hook"]], "register_full_backward_hook() (residualconnection method)": [[25, "mt_transformer.model.layers.ResidualConnection.register_full_backward_hook"]], "register_full_backward_pre_hook() (residualconnection method)": [[25, "mt_transformer.model.layers.ResidualConnection.register_full_backward_pre_hook"]], "register_load_state_dict_post_hook() (residualconnection method)": [[25, "mt_transformer.model.layers.ResidualConnection.register_load_state_dict_post_hook"]], "register_module() (residualconnection method)": [[25, "mt_transformer.model.layers.ResidualConnection.register_module"]], "register_parameter() (residualconnection method)": [[25, "mt_transformer.model.layers.ResidualConnection.register_parameter"]], "register_state_dict_pre_hook() (residualconnection method)": [[25, "mt_transformer.model.layers.ResidualConnection.register_state_dict_pre_hook"]], "requires_grad_() (residualconnection method)": [[25, "mt_transformer.model.layers.ResidualConnection.requires_grad_"]], "set_extra_state() (residualconnection method)": [[25, "mt_transformer.model.layers.ResidualConnection.set_extra_state"]], "share_memory() (residualconnection method)": [[25, "mt_transformer.model.layers.ResidualConnection.share_memory"]], "state_dict() (residualconnection method)": [[25, "mt_transformer.model.layers.ResidualConnection.state_dict"]], "to() (residualconnection method)": [[25, "mt_transformer.model.layers.ResidualConnection.to"]], "to_empty() (residualconnection method)": [[25, "mt_transformer.model.layers.ResidualConnection.to_empty"]], "train() (residualconnection method)": [[25, "mt_transformer.model.layers.ResidualConnection.train"]], "type() (residualconnection method)": [[25, "mt_transformer.model.layers.ResidualConnection.type"]], "xpu() (residualconnection method)": [[25, "mt_transformer.model.layers.ResidualConnection.xpu"]], "zero_grad() (residualconnection method)": [[25, "mt_transformer.model.layers.ResidualConnection.zero_grad"]], "tokenembeddings (class in mt_transformer.model.layers)": [[26, "mt_transformer.model.layers.TokenEmbeddings"]], "add_module() (tokenembeddings method)": [[26, "mt_transformer.model.layers.TokenEmbeddings.add_module"]], "apply() (tokenembeddings method)": [[26, "mt_transformer.model.layers.TokenEmbeddings.apply"]], "bfloat16() (tokenembeddings method)": [[26, "mt_transformer.model.layers.TokenEmbeddings.bfloat16"]], "buffers() (tokenembeddings method)": [[26, "mt_transformer.model.layers.TokenEmbeddings.buffers"]], "children() (tokenembeddings method)": [[26, "mt_transformer.model.layers.TokenEmbeddings.children"]], "compile() (tokenembeddings method)": [[26, "mt_transformer.model.layers.TokenEmbeddings.compile"]], "cpu() (tokenembeddings method)": [[26, "mt_transformer.model.layers.TokenEmbeddings.cpu"]], "cuda() (tokenembeddings method)": [[26, "mt_transformer.model.layers.TokenEmbeddings.cuda"]], "double() (tokenembeddings method)": [[26, "mt_transformer.model.layers.TokenEmbeddings.double"]], "eval() (tokenembeddings method)": [[26, "mt_transformer.model.layers.TokenEmbeddings.eval"]], "extra_repr() (tokenembeddings method)": [[26, "mt_transformer.model.layers.TokenEmbeddings.extra_repr"]], "float() (tokenembeddings method)": [[26, "mt_transformer.model.layers.TokenEmbeddings.float"]], "forward() (tokenembeddings method)": [[26, "mt_transformer.model.layers.TokenEmbeddings.forward"]], "get_buffer() (tokenembeddings method)": [[26, "mt_transformer.model.layers.TokenEmbeddings.get_buffer"]], "get_extra_state() (tokenembeddings method)": [[26, "mt_transformer.model.layers.TokenEmbeddings.get_extra_state"]], "get_parameter() (tokenembeddings method)": [[26, "mt_transformer.model.layers.TokenEmbeddings.get_parameter"]], "get_submodule() (tokenembeddings method)": [[26, "mt_transformer.model.layers.TokenEmbeddings.get_submodule"]], "half() (tokenembeddings method)": [[26, "mt_transformer.model.layers.TokenEmbeddings.half"]], "ipu() (tokenembeddings method)": [[26, "mt_transformer.model.layers.TokenEmbeddings.ipu"]], "load_state_dict() (tokenembeddings method)": [[26, "mt_transformer.model.layers.TokenEmbeddings.load_state_dict"]], "modules() (tokenembeddings method)": [[26, "mt_transformer.model.layers.TokenEmbeddings.modules"]], "named_buffers() (tokenembeddings method)": [[26, "mt_transformer.model.layers.TokenEmbeddings.named_buffers"]], "named_children() (tokenembeddings method)": [[26, "mt_transformer.model.layers.TokenEmbeddings.named_children"]], "named_modules() (tokenembeddings method)": [[26, "mt_transformer.model.layers.TokenEmbeddings.named_modules"]], "named_parameters() (tokenembeddings method)": [[26, "mt_transformer.model.layers.TokenEmbeddings.named_parameters"]], "parameters() (tokenembeddings method)": [[26, "mt_transformer.model.layers.TokenEmbeddings.parameters"]], "register_backward_hook() (tokenembeddings method)": [[26, "mt_transformer.model.layers.TokenEmbeddings.register_backward_hook"]], "register_buffer() (tokenembeddings method)": [[26, "mt_transformer.model.layers.TokenEmbeddings.register_buffer"]], "register_forward_hook() (tokenembeddings method)": [[26, "mt_transformer.model.layers.TokenEmbeddings.register_forward_hook"]], "register_forward_pre_hook() (tokenembeddings method)": [[26, "mt_transformer.model.layers.TokenEmbeddings.register_forward_pre_hook"]], "register_full_backward_hook() (tokenembeddings method)": [[26, "mt_transformer.model.layers.TokenEmbeddings.register_full_backward_hook"]], "register_full_backward_pre_hook() (tokenembeddings method)": [[26, "mt_transformer.model.layers.TokenEmbeddings.register_full_backward_pre_hook"]], "register_load_state_dict_post_hook() (tokenembeddings method)": [[26, "mt_transformer.model.layers.TokenEmbeddings.register_load_state_dict_post_hook"]], "register_module() (tokenembeddings method)": [[26, "mt_transformer.model.layers.TokenEmbeddings.register_module"]], "register_parameter() (tokenembeddings method)": [[26, "mt_transformer.model.layers.TokenEmbeddings.register_parameter"]], "register_state_dict_pre_hook() (tokenembeddings method)": [[26, "mt_transformer.model.layers.TokenEmbeddings.register_state_dict_pre_hook"]], "requires_grad_() (tokenembeddings method)": [[26, "mt_transformer.model.layers.TokenEmbeddings.requires_grad_"]], "set_extra_state() (tokenembeddings method)": [[26, "mt_transformer.model.layers.TokenEmbeddings.set_extra_state"]], "share_memory() (tokenembeddings method)": [[26, "mt_transformer.model.layers.TokenEmbeddings.share_memory"]], "state_dict() (tokenembeddings method)": [[26, "mt_transformer.model.layers.TokenEmbeddings.state_dict"]], "to() (tokenembeddings method)": [[26, "mt_transformer.model.layers.TokenEmbeddings.to"]], "to_empty() (tokenembeddings method)": [[26, "mt_transformer.model.layers.TokenEmbeddings.to_empty"]], "train() (tokenembeddings method)": [[26, "mt_transformer.model.layers.TokenEmbeddings.train"]], "type() (tokenembeddings method)": [[26, "mt_transformer.model.layers.TokenEmbeddings.type"]], "xpu() (tokenembeddings method)": [[26, "mt_transformer.model.layers.TokenEmbeddings.xpu"]], "zero_grad() (tokenembeddings method)": [[26, "mt_transformer.model.layers.TokenEmbeddings.zero_grad"]], "mt_transformer.model.transformer_model": [[27, "module-mt_transformer.model.transformer_model"]], "decoder (class in mt_transformer.model.transformer_model)": [[28, "mt_transformer.model.transformer_model.Decoder"]], "add_module() (decoder method)": [[28, "mt_transformer.model.transformer_model.Decoder.add_module"]], "apply() (decoder method)": [[28, "mt_transformer.model.transformer_model.Decoder.apply"]], "bfloat16() (decoder method)": [[28, "mt_transformer.model.transformer_model.Decoder.bfloat16"]], "buffers() (decoder method)": [[28, "mt_transformer.model.transformer_model.Decoder.buffers"]], "children() (decoder method)": [[28, "mt_transformer.model.transformer_model.Decoder.children"]], "compile() (decoder method)": [[28, "mt_transformer.model.transformer_model.Decoder.compile"]], "cpu() (decoder method)": [[28, "mt_transformer.model.transformer_model.Decoder.cpu"]], "cuda() (decoder method)": [[28, "mt_transformer.model.transformer_model.Decoder.cuda"]], "double() (decoder method)": [[28, "mt_transformer.model.transformer_model.Decoder.double"]], "eval() (decoder method)": [[28, "mt_transformer.model.transformer_model.Decoder.eval"]], "extra_repr() (decoder method)": [[28, "mt_transformer.model.transformer_model.Decoder.extra_repr"]], "float() (decoder method)": [[28, "mt_transformer.model.transformer_model.Decoder.float"]], "get_buffer() (decoder method)": [[28, "mt_transformer.model.transformer_model.Decoder.get_buffer"]], "get_extra_state() (decoder method)": [[28, "mt_transformer.model.transformer_model.Decoder.get_extra_state"]], "get_parameter() (decoder method)": [[28, "mt_transformer.model.transformer_model.Decoder.get_parameter"]], "get_submodule() (decoder method)": [[28, "mt_transformer.model.transformer_model.Decoder.get_submodule"]], "half() (decoder method)": [[28, "mt_transformer.model.transformer_model.Decoder.half"]], "ipu() (decoder method)": [[28, "mt_transformer.model.transformer_model.Decoder.ipu"]], "load_state_dict() (decoder method)": [[28, "mt_transformer.model.transformer_model.Decoder.load_state_dict"]], "modules() (decoder method)": [[28, "mt_transformer.model.transformer_model.Decoder.modules"]], "named_buffers() (decoder method)": [[28, "mt_transformer.model.transformer_model.Decoder.named_buffers"]], "named_children() (decoder method)": [[28, "mt_transformer.model.transformer_model.Decoder.named_children"]], "named_modules() (decoder method)": [[28, "mt_transformer.model.transformer_model.Decoder.named_modules"]], "named_parameters() (decoder method)": [[28, "mt_transformer.model.transformer_model.Decoder.named_parameters"]], "parameters() (decoder method)": [[28, "mt_transformer.model.transformer_model.Decoder.parameters"]], "register_backward_hook() (decoder method)": [[28, "mt_transformer.model.transformer_model.Decoder.register_backward_hook"]], "register_buffer() (decoder method)": [[28, "mt_transformer.model.transformer_model.Decoder.register_buffer"]], "register_forward_hook() (decoder method)": [[28, "mt_transformer.model.transformer_model.Decoder.register_forward_hook"]], "register_forward_pre_hook() (decoder method)": [[28, "mt_transformer.model.transformer_model.Decoder.register_forward_pre_hook"]], "register_full_backward_hook() (decoder method)": [[28, "mt_transformer.model.transformer_model.Decoder.register_full_backward_hook"]], "register_full_backward_pre_hook() (decoder method)": [[28, "mt_transformer.model.transformer_model.Decoder.register_full_backward_pre_hook"]], "register_load_state_dict_post_hook() (decoder method)": [[28, "mt_transformer.model.transformer_model.Decoder.register_load_state_dict_post_hook"]], "register_module() (decoder method)": [[28, "mt_transformer.model.transformer_model.Decoder.register_module"]], "register_parameter() (decoder method)": [[28, "mt_transformer.model.transformer_model.Decoder.register_parameter"]], "register_state_dict_pre_hook() (decoder method)": [[28, "mt_transformer.model.transformer_model.Decoder.register_state_dict_pre_hook"]], "requires_grad_() (decoder method)": [[28, "mt_transformer.model.transformer_model.Decoder.requires_grad_"]], "set_extra_state() (decoder method)": [[28, "mt_transformer.model.transformer_model.Decoder.set_extra_state"]], "share_memory() (decoder method)": [[28, "mt_transformer.model.transformer_model.Decoder.share_memory"]], "state_dict() (decoder method)": [[28, "mt_transformer.model.transformer_model.Decoder.state_dict"]], "to() (decoder method)": [[28, "mt_transformer.model.transformer_model.Decoder.to"]], "to_empty() (decoder method)": [[28, "mt_transformer.model.transformer_model.Decoder.to_empty"]], "train() (decoder method)": [[28, "mt_transformer.model.transformer_model.Decoder.train"]], "type() (decoder method)": [[28, "mt_transformer.model.transformer_model.Decoder.type"]], "xpu() (decoder method)": [[28, "mt_transformer.model.transformer_model.Decoder.xpu"]], "zero_grad() (decoder method)": [[28, "mt_transformer.model.transformer_model.Decoder.zero_grad"]], "decoderstack (class in mt_transformer.model.transformer_model)": [[29, "mt_transformer.model.transformer_model.DecoderStack"]], "add_module() (decoderstack method)": [[29, "mt_transformer.model.transformer_model.DecoderStack.add_module"]], "apply() (decoderstack method)": [[29, "mt_transformer.model.transformer_model.DecoderStack.apply"]], "bfloat16() (decoderstack method)": [[29, "mt_transformer.model.transformer_model.DecoderStack.bfloat16"]], "buffers() (decoderstack method)": [[29, "mt_transformer.model.transformer_model.DecoderStack.buffers"]], "children() (decoderstack method)": [[29, "mt_transformer.model.transformer_model.DecoderStack.children"]], "compile() (decoderstack method)": [[29, "mt_transformer.model.transformer_model.DecoderStack.compile"]], "cpu() (decoderstack method)": [[29, "mt_transformer.model.transformer_model.DecoderStack.cpu"]], "cuda() (decoderstack method)": [[29, "mt_transformer.model.transformer_model.DecoderStack.cuda"]], "double() (decoderstack method)": [[29, "mt_transformer.model.transformer_model.DecoderStack.double"]], "eval() (decoderstack method)": [[29, "mt_transformer.model.transformer_model.DecoderStack.eval"]], "extra_repr() (decoderstack method)": [[29, "mt_transformer.model.transformer_model.DecoderStack.extra_repr"]], "float() (decoderstack method)": [[29, "mt_transformer.model.transformer_model.DecoderStack.float"]], "forward() (decoderstack method)": [[29, "mt_transformer.model.transformer_model.DecoderStack.forward"]], "get_buffer() (decoderstack method)": [[29, "mt_transformer.model.transformer_model.DecoderStack.get_buffer"]], "get_extra_state() (decoderstack method)": [[29, "mt_transformer.model.transformer_model.DecoderStack.get_extra_state"]], "get_parameter() (decoderstack method)": [[29, "mt_transformer.model.transformer_model.DecoderStack.get_parameter"]], "get_submodule() (decoderstack method)": [[29, "mt_transformer.model.transformer_model.DecoderStack.get_submodule"]], "half() (decoderstack method)": [[29, "mt_transformer.model.transformer_model.DecoderStack.half"]], "ipu() (decoderstack method)": [[29, "mt_transformer.model.transformer_model.DecoderStack.ipu"]], "load_state_dict() (decoderstack method)": [[29, "mt_transformer.model.transformer_model.DecoderStack.load_state_dict"]], "modules() (decoderstack method)": [[29, "mt_transformer.model.transformer_model.DecoderStack.modules"]], "named_buffers() (decoderstack method)": [[29, "mt_transformer.model.transformer_model.DecoderStack.named_buffers"]], "named_children() (decoderstack method)": [[29, "mt_transformer.model.transformer_model.DecoderStack.named_children"]], "named_modules() (decoderstack method)": [[29, "mt_transformer.model.transformer_model.DecoderStack.named_modules"]], "named_parameters() (decoderstack method)": [[29, "mt_transformer.model.transformer_model.DecoderStack.named_parameters"]], "parameters() (decoderstack method)": [[29, "mt_transformer.model.transformer_model.DecoderStack.parameters"]], "register_backward_hook() (decoderstack method)": [[29, "mt_transformer.model.transformer_model.DecoderStack.register_backward_hook"]], "register_buffer() (decoderstack method)": [[29, "mt_transformer.model.transformer_model.DecoderStack.register_buffer"]], "register_forward_hook() (decoderstack method)": [[29, "mt_transformer.model.transformer_model.DecoderStack.register_forward_hook"]], "register_forward_pre_hook() (decoderstack method)": [[29, "mt_transformer.model.transformer_model.DecoderStack.register_forward_pre_hook"]], "register_full_backward_hook() (decoderstack method)": [[29, "mt_transformer.model.transformer_model.DecoderStack.register_full_backward_hook"]], "register_full_backward_pre_hook() (decoderstack method)": [[29, "mt_transformer.model.transformer_model.DecoderStack.register_full_backward_pre_hook"]], "register_load_state_dict_post_hook() (decoderstack method)": [[29, "mt_transformer.model.transformer_model.DecoderStack.register_load_state_dict_post_hook"]], "register_module() (decoderstack method)": [[29, "mt_transformer.model.transformer_model.DecoderStack.register_module"]], "register_parameter() (decoderstack method)": [[29, "mt_transformer.model.transformer_model.DecoderStack.register_parameter"]], "register_state_dict_pre_hook() (decoderstack method)": [[29, "mt_transformer.model.transformer_model.DecoderStack.register_state_dict_pre_hook"]], "requires_grad_() (decoderstack method)": [[29, "mt_transformer.model.transformer_model.DecoderStack.requires_grad_"]], "set_extra_state() (decoderstack method)": [[29, "mt_transformer.model.transformer_model.DecoderStack.set_extra_state"]], "share_memory() (decoderstack method)": [[29, "mt_transformer.model.transformer_model.DecoderStack.share_memory"]], "state_dict() (decoderstack method)": [[29, "mt_transformer.model.transformer_model.DecoderStack.state_dict"]], "to() (decoderstack method)": [[29, "mt_transformer.model.transformer_model.DecoderStack.to"]], "to_empty() (decoderstack method)": [[29, "mt_transformer.model.transformer_model.DecoderStack.to_empty"]], "train() (decoderstack method)": [[29, "mt_transformer.model.transformer_model.DecoderStack.train"]], "type() (decoderstack method)": [[29, "mt_transformer.model.transformer_model.DecoderStack.type"]], "xpu() (decoderstack method)": [[29, "mt_transformer.model.transformer_model.DecoderStack.xpu"]], "zero_grad() (decoderstack method)": [[29, "mt_transformer.model.transformer_model.DecoderStack.zero_grad"]], "encoder (class in mt_transformer.model.transformer_model)": [[30, "mt_transformer.model.transformer_model.Encoder"]], "add_module() (encoder method)": [[30, "mt_transformer.model.transformer_model.Encoder.add_module"]], "apply() (encoder method)": [[30, "mt_transformer.model.transformer_model.Encoder.apply"]], "bfloat16() (encoder method)": [[30, "mt_transformer.model.transformer_model.Encoder.bfloat16"]], "buffers() (encoder method)": [[30, "mt_transformer.model.transformer_model.Encoder.buffers"]], "children() (encoder method)": [[30, "mt_transformer.model.transformer_model.Encoder.children"]], "compile() (encoder method)": [[30, "mt_transformer.model.transformer_model.Encoder.compile"]], "cpu() (encoder method)": [[30, "mt_transformer.model.transformer_model.Encoder.cpu"]], "cuda() (encoder method)": [[30, "mt_transformer.model.transformer_model.Encoder.cuda"]], "double() (encoder method)": [[30, "mt_transformer.model.transformer_model.Encoder.double"]], "eval() (encoder method)": [[30, "mt_transformer.model.transformer_model.Encoder.eval"]], "extra_repr() (encoder method)": [[30, "mt_transformer.model.transformer_model.Encoder.extra_repr"]], "float() (encoder method)": [[30, "mt_transformer.model.transformer_model.Encoder.float"]], "get_buffer() (encoder method)": [[30, "mt_transformer.model.transformer_model.Encoder.get_buffer"]], "get_extra_state() (encoder method)": [[30, "mt_transformer.model.transformer_model.Encoder.get_extra_state"]], "get_parameter() (encoder method)": [[30, "mt_transformer.model.transformer_model.Encoder.get_parameter"]], "get_submodule() (encoder method)": [[30, "mt_transformer.model.transformer_model.Encoder.get_submodule"]], "half() (encoder method)": [[30, "mt_transformer.model.transformer_model.Encoder.half"]], "ipu() (encoder method)": [[30, "mt_transformer.model.transformer_model.Encoder.ipu"]], "load_state_dict() (encoder method)": [[30, "mt_transformer.model.transformer_model.Encoder.load_state_dict"]], "modules() (encoder method)": [[30, "mt_transformer.model.transformer_model.Encoder.modules"]], "named_buffers() (encoder method)": [[30, "mt_transformer.model.transformer_model.Encoder.named_buffers"]], "named_children() (encoder method)": [[30, "mt_transformer.model.transformer_model.Encoder.named_children"]], "named_modules() (encoder method)": [[30, "mt_transformer.model.transformer_model.Encoder.named_modules"]], "named_parameters() (encoder method)": [[30, "mt_transformer.model.transformer_model.Encoder.named_parameters"]], "parameters() (encoder method)": [[30, "mt_transformer.model.transformer_model.Encoder.parameters"]], "register_backward_hook() (encoder method)": [[30, "mt_transformer.model.transformer_model.Encoder.register_backward_hook"]], "register_buffer() (encoder method)": [[30, "mt_transformer.model.transformer_model.Encoder.register_buffer"]], "register_forward_hook() (encoder method)": [[30, "mt_transformer.model.transformer_model.Encoder.register_forward_hook"]], "register_forward_pre_hook() (encoder method)": [[30, "mt_transformer.model.transformer_model.Encoder.register_forward_pre_hook"]], "register_full_backward_hook() (encoder method)": [[30, "mt_transformer.model.transformer_model.Encoder.register_full_backward_hook"]], "register_full_backward_pre_hook() (encoder method)": [[30, "mt_transformer.model.transformer_model.Encoder.register_full_backward_pre_hook"]], "register_load_state_dict_post_hook() (encoder method)": [[30, "mt_transformer.model.transformer_model.Encoder.register_load_state_dict_post_hook"]], "register_module() (encoder method)": [[30, "mt_transformer.model.transformer_model.Encoder.register_module"]], "register_parameter() (encoder method)": [[30, "mt_transformer.model.transformer_model.Encoder.register_parameter"]], "register_state_dict_pre_hook() (encoder method)": [[30, "mt_transformer.model.transformer_model.Encoder.register_state_dict_pre_hook"]], "requires_grad_() (encoder method)": [[30, "mt_transformer.model.transformer_model.Encoder.requires_grad_"]], "set_extra_state() (encoder method)": [[30, "mt_transformer.model.transformer_model.Encoder.set_extra_state"]], "share_memory() (encoder method)": [[30, "mt_transformer.model.transformer_model.Encoder.share_memory"]], "state_dict() (encoder method)": [[30, "mt_transformer.model.transformer_model.Encoder.state_dict"]], "to() (encoder method)": [[30, "mt_transformer.model.transformer_model.Encoder.to"]], "to_empty() (encoder method)": [[30, "mt_transformer.model.transformer_model.Encoder.to_empty"]], "train() (encoder method)": [[30, "mt_transformer.model.transformer_model.Encoder.train"]], "type() (encoder method)": [[30, "mt_transformer.model.transformer_model.Encoder.type"]], "xpu() (encoder method)": [[30, "mt_transformer.model.transformer_model.Encoder.xpu"]], "zero_grad() (encoder method)": [[30, "mt_transformer.model.transformer_model.Encoder.zero_grad"]], "encoderstackold (class in mt_transformer.model.transformer_model)": [[31, "mt_transformer.model.transformer_model.EncoderStackOld"]], "add_module() (encoderstackold method)": [[31, "mt_transformer.model.transformer_model.EncoderStackOld.add_module"]], "apply() (encoderstackold method)": [[31, "mt_transformer.model.transformer_model.EncoderStackOld.apply"]], "bfloat16() (encoderstackold method)": [[31, "mt_transformer.model.transformer_model.EncoderStackOld.bfloat16"]], "buffers() (encoderstackold method)": [[31, "mt_transformer.model.transformer_model.EncoderStackOld.buffers"]], "children() (encoderstackold method)": [[31, "mt_transformer.model.transformer_model.EncoderStackOld.children"]], "compile() (encoderstackold method)": [[31, "mt_transformer.model.transformer_model.EncoderStackOld.compile"]], "cpu() (encoderstackold method)": [[31, "mt_transformer.model.transformer_model.EncoderStackOld.cpu"]], "cuda() (encoderstackold method)": [[31, "mt_transformer.model.transformer_model.EncoderStackOld.cuda"]], "double() (encoderstackold method)": [[31, "mt_transformer.model.transformer_model.EncoderStackOld.double"]], "eval() (encoderstackold method)": [[31, "mt_transformer.model.transformer_model.EncoderStackOld.eval"]], "extra_repr() (encoderstackold method)": [[31, "mt_transformer.model.transformer_model.EncoderStackOld.extra_repr"]], "float() (encoderstackold method)": [[31, "mt_transformer.model.transformer_model.EncoderStackOld.float"]], "forward() (encoderstackold method)": [[31, "mt_transformer.model.transformer_model.EncoderStackOld.forward"]], "get_buffer() (encoderstackold method)": [[31, "mt_transformer.model.transformer_model.EncoderStackOld.get_buffer"]], "get_extra_state() (encoderstackold method)": [[31, "mt_transformer.model.transformer_model.EncoderStackOld.get_extra_state"]], "get_parameter() (encoderstackold method)": [[31, "mt_transformer.model.transformer_model.EncoderStackOld.get_parameter"]], "get_submodule() (encoderstackold method)": [[31, "mt_transformer.model.transformer_model.EncoderStackOld.get_submodule"]], "half() (encoderstackold method)": [[31, "mt_transformer.model.transformer_model.EncoderStackOld.half"]], "ipu() (encoderstackold method)": [[31, "mt_transformer.model.transformer_model.EncoderStackOld.ipu"]], "load_state_dict() (encoderstackold method)": [[31, "mt_transformer.model.transformer_model.EncoderStackOld.load_state_dict"]], "modules() (encoderstackold method)": [[31, "mt_transformer.model.transformer_model.EncoderStackOld.modules"]], "named_buffers() (encoderstackold method)": [[31, "mt_transformer.model.transformer_model.EncoderStackOld.named_buffers"]], "named_children() (encoderstackold method)": [[31, "mt_transformer.model.transformer_model.EncoderStackOld.named_children"]], "named_modules() (encoderstackold method)": [[31, "mt_transformer.model.transformer_model.EncoderStackOld.named_modules"]], "named_parameters() (encoderstackold method)": [[31, "mt_transformer.model.transformer_model.EncoderStackOld.named_parameters"]], "parameters() (encoderstackold method)": [[31, "mt_transformer.model.transformer_model.EncoderStackOld.parameters"]], "register_backward_hook() (encoderstackold method)": [[31, "mt_transformer.model.transformer_model.EncoderStackOld.register_backward_hook"]], "register_buffer() (encoderstackold method)": [[31, "mt_transformer.model.transformer_model.EncoderStackOld.register_buffer"]], "register_forward_hook() (encoderstackold method)": [[31, "mt_transformer.model.transformer_model.EncoderStackOld.register_forward_hook"]], "register_forward_pre_hook() (encoderstackold method)": [[31, "mt_transformer.model.transformer_model.EncoderStackOld.register_forward_pre_hook"]], "register_full_backward_hook() (encoderstackold method)": [[31, "mt_transformer.model.transformer_model.EncoderStackOld.register_full_backward_hook"]], "register_full_backward_pre_hook() (encoderstackold method)": [[31, "mt_transformer.model.transformer_model.EncoderStackOld.register_full_backward_pre_hook"]], "register_load_state_dict_post_hook() (encoderstackold method)": [[31, "mt_transformer.model.transformer_model.EncoderStackOld.register_load_state_dict_post_hook"]], "register_module() (encoderstackold method)": [[31, "mt_transformer.model.transformer_model.EncoderStackOld.register_module"]], "register_parameter() (encoderstackold method)": [[31, "mt_transformer.model.transformer_model.EncoderStackOld.register_parameter"]], "register_state_dict_pre_hook() (encoderstackold method)": [[31, "mt_transformer.model.transformer_model.EncoderStackOld.register_state_dict_pre_hook"]], "requires_grad_() (encoderstackold method)": [[31, "mt_transformer.model.transformer_model.EncoderStackOld.requires_grad_"]], "set_extra_state() (encoderstackold method)": [[31, "mt_transformer.model.transformer_model.EncoderStackOld.set_extra_state"]], "share_memory() (encoderstackold method)": [[31, "mt_transformer.model.transformer_model.EncoderStackOld.share_memory"]], "state_dict() (encoderstackold method)": [[31, "mt_transformer.model.transformer_model.EncoderStackOld.state_dict"]], "to() (encoderstackold method)": [[31, "mt_transformer.model.transformer_model.EncoderStackOld.to"]], "to_empty() (encoderstackold method)": [[31, "mt_transformer.model.transformer_model.EncoderStackOld.to_empty"]], "train() (encoderstackold method)": [[31, "mt_transformer.model.transformer_model.EncoderStackOld.train"]], "type() (encoderstackold method)": [[31, "mt_transformer.model.transformer_model.EncoderStackOld.type"]], "xpu() (encoderstackold method)": [[31, "mt_transformer.model.transformer_model.EncoderStackOld.xpu"]], "zero_grad() (encoderstackold method)": [[31, "mt_transformer.model.transformer_model.EncoderStackOld.zero_grad"]], "transformer (class in mt_transformer.model.transformer_model)": [[32, "mt_transformer.model.transformer_model.Transformer"]], "add_module() (transformer method)": [[32, "mt_transformer.model.transformer_model.Transformer.add_module"]], "apply() (transformer method)": [[32, "mt_transformer.model.transformer_model.Transformer.apply"]], "bfloat16() (transformer method)": [[32, "mt_transformer.model.transformer_model.Transformer.bfloat16"]], "buffers() (transformer method)": [[32, "mt_transformer.model.transformer_model.Transformer.buffers"]], "children() (transformer method)": [[32, "mt_transformer.model.transformer_model.Transformer.children"]], "compile() (transformer method)": [[32, "mt_transformer.model.transformer_model.Transformer.compile"]], "cpu() (transformer method)": [[32, "mt_transformer.model.transformer_model.Transformer.cpu"]], "cuda() (transformer method)": [[32, "mt_transformer.model.transformer_model.Transformer.cuda"]], "double() (transformer method)": [[32, "mt_transformer.model.transformer_model.Transformer.double"]], "eval() (transformer method)": [[32, "mt_transformer.model.transformer_model.Transformer.eval"]], "extra_repr() (transformer method)": [[32, "mt_transformer.model.transformer_model.Transformer.extra_repr"]], "float() (transformer method)": [[32, "mt_transformer.model.transformer_model.Transformer.float"]], "forward() (transformer method)": [[32, "mt_transformer.model.transformer_model.Transformer.forward"]], "get_buffer() (transformer method)": [[32, "mt_transformer.model.transformer_model.Transformer.get_buffer"]], "get_extra_state() (transformer method)": [[32, "mt_transformer.model.transformer_model.Transformer.get_extra_state"]], "get_parameter() (transformer method)": [[32, "mt_transformer.model.transformer_model.Transformer.get_parameter"]], "get_submodule() (transformer method)": [[32, "mt_transformer.model.transformer_model.Transformer.get_submodule"]], "half() (transformer method)": [[32, "mt_transformer.model.transformer_model.Transformer.half"]], "ipu() (transformer method)": [[32, "mt_transformer.model.transformer_model.Transformer.ipu"]], "load_state_dict() (transformer method)": [[32, "mt_transformer.model.transformer_model.Transformer.load_state_dict"]], "modules() (transformer method)": [[32, "mt_transformer.model.transformer_model.Transformer.modules"]], "named_buffers() (transformer method)": [[32, "mt_transformer.model.transformer_model.Transformer.named_buffers"]], "named_children() (transformer method)": [[32, "mt_transformer.model.transformer_model.Transformer.named_children"]], "named_modules() (transformer method)": [[32, "mt_transformer.model.transformer_model.Transformer.named_modules"]], "named_parameters() (transformer method)": [[32, "mt_transformer.model.transformer_model.Transformer.named_parameters"]], "parameters() (transformer method)": [[32, "mt_transformer.model.transformer_model.Transformer.parameters"]], "register_backward_hook() (transformer method)": [[32, "mt_transformer.model.transformer_model.Transformer.register_backward_hook"]], "register_buffer() (transformer method)": [[32, "mt_transformer.model.transformer_model.Transformer.register_buffer"]], "register_forward_hook() (transformer method)": [[32, "mt_transformer.model.transformer_model.Transformer.register_forward_hook"]], "register_forward_pre_hook() (transformer method)": [[32, "mt_transformer.model.transformer_model.Transformer.register_forward_pre_hook"]], "register_full_backward_hook() (transformer method)": [[32, "mt_transformer.model.transformer_model.Transformer.register_full_backward_hook"]], "register_full_backward_pre_hook() (transformer method)": [[32, "mt_transformer.model.transformer_model.Transformer.register_full_backward_pre_hook"]], "register_load_state_dict_post_hook() (transformer method)": [[32, "mt_transformer.model.transformer_model.Transformer.register_load_state_dict_post_hook"]], "register_module() (transformer method)": [[32, "mt_transformer.model.transformer_model.Transformer.register_module"]], "register_parameter() (transformer method)": [[32, "mt_transformer.model.transformer_model.Transformer.register_parameter"]], "register_state_dict_pre_hook() (transformer method)": [[32, "mt_transformer.model.transformer_model.Transformer.register_state_dict_pre_hook"]], "requires_grad_() (transformer method)": [[32, "mt_transformer.model.transformer_model.Transformer.requires_grad_"]], "set_extra_state() (transformer method)": [[32, "mt_transformer.model.transformer_model.Transformer.set_extra_state"]], "share_memory() (transformer method)": [[32, "mt_transformer.model.transformer_model.Transformer.share_memory"]], "state_dict() (transformer method)": [[32, "mt_transformer.model.transformer_model.Transformer.state_dict"]], "to() (transformer method)": [[32, "mt_transformer.model.transformer_model.Transformer.to"]], "to_empty() (transformer method)": [[32, "mt_transformer.model.transformer_model.Transformer.to_empty"]], "train() (transformer method)": [[32, "mt_transformer.model.transformer_model.Transformer.train"]], "type() (transformer method)": [[32, "mt_transformer.model.transformer_model.Transformer.type"]], "xpu() (transformer method)": [[32, "mt_transformer.model.transformer_model.Transformer.xpu"]], "zero_grad() (transformer method)": [[32, "mt_transformer.model.transformer_model.Transformer.zero_grad"]], "transformermodel (class in mt_transformer.model.transformer_model)": [[33, "mt_transformer.model.transformer_model.TransformerModel"]], "add_module() (transformermodel method)": [[33, "mt_transformer.model.transformer_model.TransformerModel.add_module"]], "apply() (transformermodel method)": [[33, "mt_transformer.model.transformer_model.TransformerModel.apply"]], "bfloat16() (transformermodel method)": [[33, "mt_transformer.model.transformer_model.TransformerModel.bfloat16"]], "buffers() (transformermodel method)": [[33, "mt_transformer.model.transformer_model.TransformerModel.buffers"]], "children() (transformermodel method)": [[33, "mt_transformer.model.transformer_model.TransformerModel.children"]], "compile() (transformermodel method)": [[33, "mt_transformer.model.transformer_model.TransformerModel.compile"]], "cpu() (transformermodel method)": [[33, "mt_transformer.model.transformer_model.TransformerModel.cpu"]], "cuda() (transformermodel method)": [[33, "mt_transformer.model.transformer_model.TransformerModel.cuda"]], "double() (transformermodel method)": [[33, "mt_transformer.model.transformer_model.TransformerModel.double"]], "eval() (transformermodel method)": [[33, "mt_transformer.model.transformer_model.TransformerModel.eval"]], "extra_repr() (transformermodel method)": [[33, "mt_transformer.model.transformer_model.TransformerModel.extra_repr"]], "float() (transformermodel method)": [[33, "mt_transformer.model.transformer_model.TransformerModel.float"]], "forward() (transformermodel method)": [[33, "mt_transformer.model.transformer_model.TransformerModel.forward"]], "get_buffer() (transformermodel method)": [[33, "mt_transformer.model.transformer_model.TransformerModel.get_buffer"]], "get_extra_state() (transformermodel method)": [[33, "mt_transformer.model.transformer_model.TransformerModel.get_extra_state"]], "get_parameter() (transformermodel method)": [[33, "mt_transformer.model.transformer_model.TransformerModel.get_parameter"]], "get_submodule() (transformermodel method)": [[33, "mt_transformer.model.transformer_model.TransformerModel.get_submodule"]], "half() (transformermodel method)": [[33, "mt_transformer.model.transformer_model.TransformerModel.half"]], "ipu() (transformermodel method)": [[33, "mt_transformer.model.transformer_model.TransformerModel.ipu"]], "load_state_dict() (transformermodel method)": [[33, "mt_transformer.model.transformer_model.TransformerModel.load_state_dict"]], "modules() (transformermodel method)": [[33, "mt_transformer.model.transformer_model.TransformerModel.modules"]], "named_buffers() (transformermodel method)": [[33, "mt_transformer.model.transformer_model.TransformerModel.named_buffers"]], "named_children() (transformermodel method)": [[33, "mt_transformer.model.transformer_model.TransformerModel.named_children"]], "named_modules() (transformermodel method)": [[33, "mt_transformer.model.transformer_model.TransformerModel.named_modules"]], "named_parameters() (transformermodel method)": [[33, "mt_transformer.model.transformer_model.TransformerModel.named_parameters"]], "parameters() (transformermodel method)": [[33, "mt_transformer.model.transformer_model.TransformerModel.parameters"]], "register_backward_hook() (transformermodel method)": [[33, "mt_transformer.model.transformer_model.TransformerModel.register_backward_hook"]], "register_buffer() (transformermodel method)": [[33, "mt_transformer.model.transformer_model.TransformerModel.register_buffer"]], "register_forward_hook() (transformermodel method)": [[33, "mt_transformer.model.transformer_model.TransformerModel.register_forward_hook"]], "register_forward_pre_hook() (transformermodel method)": [[33, "mt_transformer.model.transformer_model.TransformerModel.register_forward_pre_hook"]], "register_full_backward_hook() (transformermodel method)": [[33, "mt_transformer.model.transformer_model.TransformerModel.register_full_backward_hook"]], "register_full_backward_pre_hook() (transformermodel method)": [[33, "mt_transformer.model.transformer_model.TransformerModel.register_full_backward_pre_hook"]], "register_load_state_dict_post_hook() (transformermodel method)": [[33, "mt_transformer.model.transformer_model.TransformerModel.register_load_state_dict_post_hook"]], "register_module() (transformermodel method)": [[33, "mt_transformer.model.transformer_model.TransformerModel.register_module"]], "register_parameter() (transformermodel method)": [[33, "mt_transformer.model.transformer_model.TransformerModel.register_parameter"]], "register_state_dict_pre_hook() (transformermodel method)": [[33, "mt_transformer.model.transformer_model.TransformerModel.register_state_dict_pre_hook"]], "requires_grad_() (transformermodel method)": [[33, "mt_transformer.model.transformer_model.TransformerModel.requires_grad_"]], "set_extra_state() (transformermodel method)": [[33, "mt_transformer.model.transformer_model.TransformerModel.set_extra_state"]], "share_memory() (transformermodel method)": [[33, "mt_transformer.model.transformer_model.TransformerModel.share_memory"]], "state_dict() (transformermodel method)": [[33, "mt_transformer.model.transformer_model.TransformerModel.state_dict"]], "to() (transformermodel method)": [[33, "mt_transformer.model.transformer_model.TransformerModel.to"]], "to_empty() (transformermodel method)": [[33, "mt_transformer.model.transformer_model.TransformerModel.to_empty"]], "train() (transformermodel method)": [[33, "mt_transformer.model.transformer_model.TransformerModel.train"]], "type() (transformermodel method)": [[33, "mt_transformer.model.transformer_model.TransformerModel.type"]], "xpu() (transformermodel method)": [[33, "mt_transformer.model.transformer_model.TransformerModel.xpu"]], "zero_grad() (transformermodel method)": [[33, "mt_transformer.model.transformer_model.TransformerModel.zero_grad"]], "create_transformer() (in module mt_transformer.model.transformer_model)": [[34, "mt_transformer.model.transformer_model.create_transformer"]], "get_transformer_model() (in module mt_transformer.model.transformer_model)": [[35, "mt_transformer.model.transformer_model.get_transformer_model"]], "mt_transformer.trainer": [[36, "module-mt_transformer.trainer"]], "mt_transformer.trainer.transformer_trainer": [[37, "module-mt_transformer.trainer.transformer_trainer"]], "transformertrainer (class in mt_transformer.trainer.transformer_trainer)": [[38, "mt_transformer.trainer.transformer_trainer.TransformerTrainer"]], "mt_transformer.trainer.transformer_validator": [[39, "module-mt_transformer.trainer.transformer_validator"]], "transformervalidator (class in mt_transformer.trainer.transformer_validator)": [[40, "mt_transformer.trainer.transformer_validator.TransformerValidator"]]}})